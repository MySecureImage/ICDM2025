{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0fstZUAhsMQLllAZaT4Al"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J5gsJdwkCM4u"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from statsmodels.stats.anova import anova_lm\n","from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n","\n","def load_and_prepare_data(file_path):\n","    \"\"\"\n","    Load and prepare the data for analysis.\n","\n","    Parameters:\n","    -----------\n","    file_path : str\n","        Path to the CSV file\n","\n","    Returns:\n","    --------\n","    pandas.DataFrame\n","        Prepared dataframe for analysis\n","    \"\"\"\n","    # Load data - adjust parameters based on your file format\n","    df = pd.read_csv(file_path)\n","\n","    # Ensure factor variables are treated as categorical\n","    categorical_cols = ['Dataset', 'Approach', 'Factors', 'Dims']\n","    for col in categorical_cols:\n","        if col in df.columns:\n","            df[col] = df[col].astype('category')\n","\n","    # Convert 'Factors' and 'Dims' to string to treat them as categorical factors\n","    # This is important for the interaction analysis\n","    if 'Factors' in df.columns:\n","        df['Factors'] = df['Factors'].astype(str)\n","    if 'Dims' in df.columns:\n","        df['Dims'] = df['Dims'].astype(str)\n","\n","    return df\n","\n","def fit_linear_mixed_model(df, response_var='Combined_Score'):\n","    \"\"\"\n","    Fit a linear mixed model with Dataset as a random effect and\n","    Approach, Factors, and Dims as fixed effects.\n","\n","    Parameters:\n","    -----------\n","    df : pandas.DataFrame\n","        The dataset\n","    response_var : str\n","        The response variable to model\n","\n","    Returns:\n","    --------\n","    MixedLM object\n","        Fitted model\n","    \"\"\"\n","    # Create formula for the mixed model\n","    # Include main effects and interactions\n","    formula = (f\"{response_var} ~ Approach * Factors * Dims\")\n","\n","    # Fit the mixed effects model with Dataset as a random effect\n","    model = smf.mixedlm(\n","        formula=formula,\n","        data=df,\n","        groups=df['Dataset']\n","    )\n","    result = model.fit()\n","\n","    return result\n","\n","def perform_anova(fitted_model, df, response_var='Combined_Score'):\n","    \"\"\"\n","    Perform ANOVA on the model using a Type II approach.\n","\n","    Parameters:\n","    -----------\n","    fitted_model : MixedLM object\n","        The fitted mixed model\n","    df : pandas.DataFrame\n","        The original dataframe\n","    response_var : str\n","        The response variable name\n","\n","    Returns:\n","    --------\n","    pandas.DataFrame\n","        ANOVA table\n","    \"\"\"\n","    # Create a formula for OLS model that matches your mixed model\n","    formula = f\"{response_var} ~ Approach * Factors * Dims\"\n","\n","    # Fit OLS model using the formula API (this will have design_info)\n","    ols_model = smf.ols(formula=formula, data=df)\n","    ols_result = ols_model.fit()\n","\n","    # Perform ANOVA test using the OLS model\n","    anova_table = sm.stats.anova_lm(ols_result, typ=2)  # Type II ANOVA\n","\n","    return anova_table\n","\n","\n","def perform_post_hoc_tests(df, response_var='Combined_Score'):\n","    \"\"\"\n","    Perform post-hoc tests (Tukey's HSD) to compare approaches.\n","    \"\"\"\n","    # Create a multi-comparison object\n","    mc = MultiComparison(df[response_var], df['Approach'])\n","\n","    # Perform Tukey's HSD test\n","    tukey_result = mc.tukeyhsd()\n","\n","    return mc, tukey_result\n","\n","def visualize_approach_performance(df, response_var='Combined_Score'):\n","    \"\"\"\n","    Create visualizations to compare approaches' performance.\n","\n","    Parameters:\n","    -----------\n","    df : pandas.DataFrame\n","        The dataset\n","    response_var : str\n","        The response variable\n","\n","    Returns:\n","    --------\n","    matplotlib.figure.Figure\n","        The created figure\n","    \"\"\"\n","    # Create a figure with multiple subplots\n","    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n","\n","    # 1. Overall performance by approach\n","    sns.boxplot(x='Approach', y=response_var, data=df, ax=axes[0, 0])\n","    axes[0, 0].set_title(f'Distribution of {response_var} by Approach')\n","    axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45, ha='right')\n","\n","    # 2. Performance by approach and dataset\n","    sns.boxplot(x='Approach', y=response_var, hue='Dataset', data=df, ax=axes[0, 1])\n","    axes[0, 1].set_title(f'{response_var} by Approach and Dataset')\n","    axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha='right')\n","    axes[0, 1].legend(loc='upper right', bbox_to_anchor=(1.25, 1))\n","\n","    # 3. Performance by approach and factors\n","    sns.boxplot(x='Approach', y=response_var, hue='Factors', data=df, ax=axes[1, 0])\n","    axes[1, 0].set_title(f'{response_var} by Approach and Factors')\n","    axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45, ha='right')\n","\n","    # 4. Performance by approach and dimensions\n","    sns.boxplot(x='Approach', y=response_var, hue='Dims', data=df, ax=axes[1, 1])\n","    axes[1, 1].set_title(f'{response_var} by Approach and Dimensions')\n","    axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45, ha='right')\n","\n","    plt.tight_layout()\n","    return fig\n","\n","def analyze_interaction_effects(df, response_var='Combined_Score'):\n","    \"\"\"\n","    Analyze and visualize interaction effects between factors.\n","\n","    Parameters:\n","    -----------\n","    df : pandas.DataFrame\n","        The dataset\n","    response_var : str\n","        The response variable\n","\n","    Returns:\n","    --------\n","    matplotlib.figure.Figure\n","        The created figure\n","    \"\"\"\n","    # Create a figure with interaction plots\n","    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n","\n","    # 1. Approach x Factors interaction\n","    for approach in df['Approach'].unique():\n","        subset = df[df['Approach'] == approach]\n","        means = subset.groupby('Factors', observed=True)[response_var].mean()\n","        axes[0, 0].plot(means.index, means.values, marker='o', label=approach)\n","\n","    axes[0, 0].set_title('Interaction: Approach x Factors')\n","    axes[0, 0].set_xlabel('Number of Factors')\n","    axes[0, 0].set_ylabel(response_var)\n","    axes[0, 0].legend(loc='upper right', bbox_to_anchor=(1.25, 1))\n","\n","    # 2. Approach x Dims interaction\n","    for approach in df['Approach'].unique():\n","        subset = df[df['Approach'] == approach]\n","        means = subset.groupby('Dims', observed=True)[response_var].mean()\n","        axes[0, 1].plot(means.index, means.values, marker='o', label=approach)\n","\n","    axes[0, 1].set_title('Interaction: Approach x Dimensions')\n","    axes[0, 1].set_xlabel('Number of Dimensions')\n","    axes[0, 1].set_ylabel(response_var)\n","\n","    # 3. Dataset x Approach interaction\n","    for dataset in df['Dataset'].unique():\n","        subset = df[df['Dataset'] == dataset]\n","        means = subset.groupby('Approach', observed=True)[response_var].mean()\n","        axes[1, 0].plot(means.index, means.values, marker='o', label=dataset)\n","\n","    axes[1, 0].set_title('Interaction: Dataset x Approach')\n","    axes[1, 0].set_xlabel('Approach')\n","    axes[1, 0].set_ylabel(response_var)\n","    axes[1, 0].set_xticks(range(len(df['Approach'].unique())))\n","    axes[1, 0].set_xticklabels(df['Approach'].unique(), rotation=45, ha='right')\n","    axes[1, 0].legend(loc='upper right', bbox_to_anchor=(1.25, 1))\n","\n","    # 4. Factors x Dims interaction\n","    for factor in df['Factors'].unique():\n","        subset = df[df['Factors'] == factor]\n","        means = subset.groupby('Dims', observed=True)[response_var].mean()\n","        axes[1, 1].plot(means.index, means.values, marker='o', label=f'Factors={factor}')\n","\n","    axes[1, 1].set_title('Interaction: Factors x Dimensions')\n","    axes[1, 1].set_xlabel('Number of Dimensions')\n","    axes[1, 1].set_ylabel(response_var)\n","    axes[1, 1].legend()\n","\n","    plt.tight_layout()\n","    return fig\n","\n","def analyze_dataset_variability(df, response_var='Combined_Score'):\n","    \"\"\"\n","    Analyze variability across datasets and how it influences approach performance.\n","\n","    Parameters:\n","    -----------\n","    df : pandas.DataFrame\n","        The dataset\n","    response_var : str\n","        The response variable\n","\n","    Returns:\n","    --------\n","    tuple\n","        Results dictionary and figure\n","    \"\"\"\n","    # Create a figure for visualizing dataset variability\n","    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n","\n","    # 1. Distribution of response variable by dataset\n","    sns.boxplot(x='Dataset', y=response_var, data=df, ax=axes[0])\n","    axes[0].set_title(f'Distribution of {response_var} by Dataset')\n","\n","    # 2. Heatmap showing average performance of approaches across datasets\n","    pivot_table = df.pivot_table(\n","        values=response_var,\n","        index='Dataset',\n","        columns='Approach',\n","        aggfunc='mean',\n","        observed=True\n","    )\n","\n","    # Create heatmap\n","    sns.heatmap(pivot_table, annot=True, cmap='viridis', ax=axes[1], fmt=\".2f\")\n","    axes[1].set_title('Mean Performance by Dataset and Approach')\n","\n","    plt.tight_layout()\n","\n","    # Calculate dataset variability metrics\n","    dataset_means = df.groupby('Dataset', observed=True)[response_var].mean().to_dict()\n","    dataset_vars = df.groupby('Dataset', observed=True)[response_var].var().to_dict()\n","\n","    # Find best approach for each dataset\n","    best_approaches = {}\n","    for dataset in df['Dataset'].unique():\n","        subset = df[df['Dataset'] == dataset]\n","        best_approach = subset.groupby('Approach', observed=True)[response_var].mean().idxmax()\n","        best_approaches[dataset] = best_approach\n","\n","    # Calculate consistency of approach performance across datasets\n","    approach_consistency = {}\n","    for approach in df['Approach'].unique():\n","        subset = df[df['Approach'] == approach]\n","        # Calculate coefficient of variation across datasets\n","        means_by_dataset = subset.groupby('Dataset')[response_var].mean()\n","        cv = means_by_dataset.std() / means_by_dataset.mean()\n","        approach_consistency[approach] = {\n","            'mean': means_by_dataset.mean(),\n","            'std': means_by_dataset.std(),\n","            'cv': cv,  # Lower CV means more consistent performance\n","            'ranks': []  # Will store rank of approach in each dataset\n","        }\n","\n","    # Calculate approach rankings within each dataset\n","    for dataset in df['Dataset'].unique():\n","        subset = df[df['Dataset'] == dataset]\n","        ranks = subset.groupby('Approach')[response_var].mean().rank(ascending=False)\n","\n","        for approach in ranks.index:\n","            approach_consistency[approach]['ranks'].append(ranks[approach])\n","\n","    # Calculate average rank for each approach\n","    for approach in approach_consistency:\n","        approach_consistency[approach]['avg_rank'] = np.mean(approach_consistency[approach]['ranks'])\n","\n","    results = {\n","        'dataset_means': dataset_means,\n","        'dataset_vars': dataset_vars,\n","        'best_approaches': best_approaches,\n","        'approach_consistency': approach_consistency\n","    }\n","\n","    return results, fig\n","\n","def main(file_path, response_var='Combined_Score'):\n","    \"\"\"\n","    Main function to run the complete analysis.\n","    \"\"\"\n","    # Load and prepare data\n","    print(\"Loading and preparing data...\")\n","    df = load_and_prepare_data(file_path)\n","\n","    # Fit linear mixed model\n","    print(\"Fitting linear mixed model...\")\n","    lmm_result = fit_linear_mixed_model(df, response_var)\n","    print(\"\\nLinear Mixed Model Summary:\")\n","    print(lmm_result.summary())\n","\n","    # Perform ANOVA\n","    print(\"\\nPerforming ANOVA...\")\n","    anova_result = perform_anova(lmm_result, df, response_var)\n","    print(\"\\nANOVA Results:\")\n","    print(anova_result)\n","\n","    # --- Perform post-hoc tests ---\n","    mc, tukey_result = perform_post_hoc_tests(df, response_var)\n","    print(\"\\nTukey's HSD Results:\")\n","    print(tukey_result)\n","\n","    # --- FIXED TUKEY HANDLING ---\n","    # 1) force the group names into a NumPy array\n","    group_names = np.array(list(tukey_result.groupsunique))\n","\n","    # 2) tukey_result._multicomp.pairindices is a tuple of two index arrays\n","    idx1, idx2 = tukey_result._multicomp.pairindices\n","\n","    # 3) build the DataFrame\n","    tukey_df = pd.DataFrame({\n","        'group1':   group_names[idx1],\n","        'group2':   group_names[idx2],\n","        'meandiff': tukey_result.meandiffs,\n","        'p-adj':    tukey_result.pvalues,\n","        'reject':   tukey_result.reject\n","    })\n","\n","    # 4) filter to only those pairs where reject == True\n","    sig_pairs = tukey_df[tukey_df['reject']]\n","    # ------------------------------\n","\n","    # Create visualizations\n","    print(\"\\nCreating visualizations...\")\n","    performance_fig = visualize_approach_performance(df, response_var)\n","    interaction_fig = analyze_interaction_effects(df, response_var)\n","    dataset_results, dataset_fig = analyze_dataset_variability(df, response_var)\n","\n","    # Compile results\n","    results = {\n","        'data':            df,\n","        'lmm_result':      lmm_result,\n","        'anova_result':    anova_result,\n","        'tukey_result':    tukey_result,\n","        'sig_pairs':       sig_pairs,\n","        'dataset_analysis': dataset_results,\n","        'figures': {\n","            'performance': performance_fig,\n","            'interaction': interaction_fig,\n","            'dataset':     dataset_fig\n","        }\n","    }\n","\n","    # Print key findings\n","    print(\"\\nKey Findings:\")\n","    print(\"=============\")\n","\n","    # 1. Significant Factors\n","    print(\"\\n1. Significant Factors:\")\n","    sig_facts = anova_result[anova_result['PR(>F)'] < 0.05].index.tolist()\n","    if sig_facts:\n","        for f in sig_facts:\n","            print(f\"  - {f}: p = {anova_result.loc[f,'PR(>F)']:.4f}\")\n","    else:\n","        print(\"  - None at α = 0.05\")\n","\n","    # 2. Approach comparisons\n","    print(\"\\n2. Approach Comparison:\")\n","    if not sig_pairs.empty:\n","        print(\"  Significant pairwise differences:\")\n","        for _, row in sig_pairs.iterrows():\n","            print(f\"  - {row['group1']} vs {row['group2']}: p‑adj = {row['p-adj']:.4f}\")\n","    else:\n","        print(\"  - No significant differences between approaches at α = 0.05\")\n","\n","    # 3. Best approach by dataset\n","    print(\"\\n3. Best Approach by Dataset:\")\n","    for ds, appr in dataset_results['best_approaches'].items():\n","        mean_score = df[(df['Dataset']==ds)&(df['Approach']==appr)][response_var].mean()\n","        print(f\"  - {ds}: {appr} (mean {response_var}={mean_score:.4f})\")\n","\n","    # 4. Factors & Dims effects\n","    print(\"\\n4. Effects of Factors and Dimensions:\")\n","    for fac, m in df.groupby('Factors', observed=True)[response_var].mean().items():\n","        print(f\"  - Factors={fac}: {m:.4f}\")\n","    for dim, m in df.groupby('Dims', observed=True)[response_var].mean().items():\n","        print(f\"  - Dims={dim}:    {m:.4f}\")\n","\n","    # 5. Dataset variability\n","    print(\"\\n5. Dataset Variability:\")\n","    vars_ = dataset_results['dataset_vars']\n","    most = max(vars_, key=vars_.get)\n","    least= min(vars_, key=vars_.get)\n","    print(f\"  - Most variable: {most} (var={vars_[most]:.4f})\")\n","    print(f\"  - Least variable: {least} (var={vars_[least]:.4f})\")\n","\n","    # 6. Approach consistency\n","    print(\"\\n6. Approach Consistency:\")\n","    for appr, metr in sorted(dataset_results['approach_consistency'].items(),\n","                              key=lambda kv: kv[1]['avg_rank']):\n","        print(f\"  - {appr}: avg rank={metr['avg_rank']:.2f}, CV={metr['cv']:.4f}\")\n","\n","    return results\n","\n","\n","# Example of how to run the analysis\n","if __name__ == \"__main__\":\n","    # Replace with your actual file path\n","    file_path = \"C:/Users/taiku/Documents/universal_K_data.csv\"\n","\n","    # Run the analysis\n","    results = main(file_path)\n","\n","    # Show the figures\n","    plt.show()"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from statsmodels.stats.anova import anova_lm\n","from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 1. Load the data\n","def load_data(file_path):\n","    \"\"\"Load data from CSV file and convert columns to appropriate types\"\"\"\n","    df = pd.read_csv(file_path)\n","\n","    # Convert factors and dims to string to treat as categorical variables\n","    df['Factors'] = df['Factors'].astype(str)\n","    df['Dims'] = df['Dims'].astype(str)\n","\n","    return df\n","\n","# 2. Fit the Linear Mixed Model\n","def fit_lmm(df, response_var='Combined Score'):\n","    \"\"\"\n","    Fit a linear mixed model with Dataset as random effect\n","    and Approach, Factors, and Dims as fixed effects\n","    \"\"\"\n","    # Formula for the model with main effects and interactions\n","    formula = f\"{response_var} ~ Approach * Factors * Dims\"\n","\n","    # Fit LMM with Dataset as random effect\n","    model = smf.mixedlm(\n","        formula=formula,\n","        data=df,\n","        groups=df['Dataset']\n","    )\n","\n","    # Use robust standard errors\n","    result = model.fit(reml=True)\n","\n","    return result\n","\n","# 3. Perform ANOVA\n","def run_anova(lmm_result):\n","    \"\"\"Perform ANOVA on the fitted LMM to test significance of fixed effects\"\"\"\n","    # Extract design matrix\n","    X = lmm_result.model.exog\n","\n","    # Get names of fixed effects\n","    names = lmm_result.model.exog_names\n","\n","    # Fit OLS model for ANOVA testing\n","    ols_model = sm.OLS(lmm_result.model.endog, X)\n","    ols_result = ols_model.fit()\n","\n","    # Run ANOVA\n","    anova_table = anova_lm(ols_result)\n","\n","    return anova_table\n","\n","# 4. Post-hoc tests\n","def post_hoc_analysis(df, response_var='Combined Score'):\n","    \"\"\"Perform post-hoc Tukey's HSD tests for approach comparisons\"\"\"\n","    # Post-hoc test for Approach\n","    approach_mc = MultiComparison(df[response_var], df['Approach'])\n","    approach_result = approach_mc.tukeyhsd()\n","\n","    # Post-hoc test for Factors\n","    factor_mc = MultiComparison(df[response_var], df['Factors'])\n","    factor_result = factor_mc.tukeyhsd()\n","\n","    # Post-hoc test for Dims\n","    dim_mc = MultiComparison(df[response_var], df['Dims'])\n","    dim_result = dim_mc.tukeyhsd()\n","\n","    return {\n","        'approach': (approach_mc, approach_result),\n","        'factors': (factor_mc, factor_result),\n","        'dims': (dim_mc, dim_result)\n","    }\n","\n","# 5. Visualize interactions\n","def plot_interactions(df, response_var='Combined Score'):\n","    \"\"\"Create interaction plots to visualize relationship between factors\"\"\"\n","    # Set up the figure\n","    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n","\n","    # Approach x Dataset interaction\n","    avg_by_approach_dataset = df.groupby(['Dataset', 'Approach'], observed=True)[response_var].mean().unstack()\n","    avg_by_approach_dataset.plot(marker='o', ax=axes[0, 0])\n","    axes[0, 0].set_title('Interaction: Dataset x Approach')\n","    axes[0, 0].set_xlabel('Dataset')\n","    axes[0, 0].set_ylabel(response_var)\n","\n","    # Approach x Factors interaction\n","    avg_by_approach_factors = df.groupby(['Factors', 'Approach'], observed=True)[response_var].mean().unstack()\n","    avg_by_approach_factors.plot(marker='o', ax=axes[0, 1])\n","    axes[0, 1].set_title('Interaction: Factors x Approach')\n","    axes[0, 1].set_xlabel('Number of Factors')\n","    axes[0, 1].set_ylabel(response_var)\n","\n","    # Approach x Dims interaction\n","    avg_by_approach_dims = df.groupby(['Dims', 'Approach'], observed=True)[response_var].mean().unstack()\n","    avg_by_approach_dims.plot(marker='o', ax=axes[1, 0])\n","    axes[1, 0].set_title('Interaction: Dimensions x Approach')\n","    axes[1, 0].set_xlabel('Number of Dimensions')\n","    axes[1, 0].set_ylabel(response_var)\n","\n","    # Factors x Dims interaction\n","    factors_dims_pivot = df.pivot_table(\n","        values=response_var,\n","        index='Factors',\n","        columns='Dims',\n","        aggfunc='mean'\n","    )\n","    sns.heatmap(factors_dims_pivot, annot=True, cmap='viridis', ax=axes[1, 1])\n","    axes[1, 1].set_title('Interaction: Factors x Dimensions')\n","\n","    plt.tight_layout()\n","    return fig\n","\n","# 6. Analyze dataset variability\n","def analyze_dataset_effects(df, response_var='Combined Score'):\n","    \"\"\"Analyze how dataset affects performance of different approaches\"\"\"\n","    # Create figure\n","    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n","\n","    # Plot mean scores by approach for each dataset\n","    sns.boxplot(x='Approach', y=response_var, hue='Dataset', data=df, ax=axes[0])\n","    axes[0].set_title('Performance by Approach and Dataset')\n","    axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n","\n","    # Create heatmap of approach performance by dataset\n","    heatmap_data = df.pivot_table(\n","        values=response_var,\n","        index='Dataset',\n","        columns='Approach',\n","        aggfunc='mean'\n","    )\n","\n","    # Find the best approach for each dataset (highlight cells)\n","    best_mask = heatmap_data.apply(lambda x: x == x.max(), axis=1)\n","\n","    # Plot heatmap\n","    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='viridis', ax=axes[1])\n","    axes[1].set_title('Mean Performance by Dataset and Approach')\n","\n","    plt.tight_layout()\n","\n","    # Calculate best approach for each dataset\n","    best_approaches = {}\n","    for dataset in df['Dataset'].unique():\n","        dataset_df = df[df['Dataset'] == dataset]\n","        approach_means = dataset_df.groupby('Approach')[response_var].mean()\n","        best_approach = approach_means.idxmax()\n","        best_approaches[dataset] = (best_approach, approach_means[best_approach])\n","\n","    return best_approaches, fig\n","\n","# Main function to run the analysis\n","def main(file_path, response_var='Combined Score'):\n","    \"\"\"Run the complete analysis and return results\"\"\"\n","    print(\"Loading data...\")\n","    df = load_data(file_path)\n","\n","    print(\"\\nFitting Linear Mixed Model...\")\n","    lmm_result = fit_lmm(df, response_var)\n","    print(lmm_result.summary())\n","\n","    print(\"\\nPerforming ANOVA to test significance of fixed effects...\")\n","    anova_result = run_anova(lmm_result)\n","    print(\"\\nANOVA Results:\")\n","    print(anova_result)\n","\n","    print(\"\\nPerforming post-hoc tests (Tukey's HSD)...\")\n","    post_hoc_results = post_hoc_analysis(df, response_var)\n","\n","    print(\"\\nTukey's HSD Results for Approach:\")\n","    print(post_hoc_results['approach'][1])\n","\n","    print(\"\\nTukey's HSD Results for Factors:\")\n","    print(post_hoc_results['factors'][1])\n","\n","    print(\"\\nTukey's HSD Results for Dimensions:\")\n","    print(post_hoc_results['dims'][1])\n","\n","    print(\"\\nCreating interaction plots...\")\n","    interaction_fig = plot_interactions(df, response_var)\n","\n","    print(\"\\nAnalyzing dataset effects...\")\n","    best_approaches, dataset_fig = analyze_dataset_effects(df, response_var)\n","\n","    print(\"\\nBest approach for each dataset:\")\n","    for dataset, (approach, score) in best_approaches.items():\n","        print(f\"  - {dataset}: {approach} (score: {score:.4f})\")\n","\n","    # Summarize main findings\n","    print(\"\\nSummary of Main Findings:\")\n","    print(\"-------------------------\")\n","\n","    # Check if Approach is significant\n","    p_value_approach = anova_result.loc['Approach', 'PR(>F)'] if 'Approach' in anova_result.index else None\n","    if p_value_approach is not None and p_value_approach < 0.05:\n","        print(f\"1. Approach has a significant effect on {response_var} (p = {p_value_approach:.4f})\")\n","\n","        # Count significant pairwise comparisons\n","        approach_result = post_hoc_results['approach'][1]\n","        sig_pairs = sum(approach_result.reject)\n","\n","        if sig_pairs > 0:\n","            print(f\"   - {sig_pairs} significant pairwise differences found among approaches\")\n","\n","            # Print top 5 most significant differences\n","            pair_indices = approach_result._multicomp.pairindices\n","            approaches = approach_result.groupsunique\n","\n","            # Get pairs and their p-values\n","            pair_data = []\n","            for i, (idx1, idx2) in enumerate(pair_indices):\n","                if approach_result.reject[i]:\n","                    app1 = approaches[idx1]\n","                    app2 = approaches[idx2]\n","                    meandiff = approach_result.meandiffs[i]\n","                    pvalue = approach_result.pvalues[i]\n","                    pair_data.append((app1, app2, meandiff, pvalue))\n","\n","            # Sort by p-value (ascending)\n","            pair_data.sort(key=lambda x: x[3])\n","\n","            # Print top 5 most significant differences\n","            print(\"   - Top significant pairwise differences:\")\n","            for i, (app1, app2, meandiff, pvalue) in enumerate(pair_data[:5]):\n","                print(f\"     {app1} vs {app2}: diff = {meandiff:.4f}, p-adj = {pvalue:.4f}\")\n","    else:\n","        print(f\"1. Approach does NOT have a significant effect on {response_var}\")\n","\n","    # Check if Factors is significant\n","    p_value_factors = anova_result.loc['Factors', 'PR(>F)'] if 'Factors' in anova_result.index else None\n","    if p_value_factors is not None and p_value_factors < 0.05:\n","        print(f\"2. Number of factors has a significant effect on {response_var} (p = {p_value_factors:.4f})\")\n","\n","        # Show mean scores for different numbers of factors\n","        factor_means = df.groupby('Factors')[response_var].mean()\n","        for factor, mean in factor_means.items():\n","            print(f\"   - Factors={factor}: mean {response_var} = {mean:.4f}\")\n","    else:\n","        print(f\"2. Number of factors does NOT have a significant effect on {response_var}\")\n","\n","    # Check if Dims is significant\n","    p_value_dims = anova_result.loc['Dims', 'PR(>F)'] if 'Dims' in anova_result.index else None\n","    if p_value_dims is not None and p_value_dims < 0.05:\n","        print(f\"3. Number of dimensions has a significant effect on {response_var} (p = {p_value_dims:.4f})\")\n","\n","        # Show mean scores for different numbers of dimensions\n","        dims_means = df.groupby('Dims')[response_var].mean()\n","        for dim, mean in dims_means.items():\n","            print(f\"   - Dims={dim}: mean {response_var} = {mean:.4f}\")\n","    else:\n","        print(f\"3. Number of dimensions does NOT have a significant effect on {response_var}\")\n","\n","    # Check interaction effects\n","    interaction_terms = [term for term in anova_result.index if '*' in term]\n","    significant_interactions = [term for term in interaction_terms\n","                               if anova_result.loc[term, 'PR(>F)'] < 0.05]\n","\n","    if significant_interactions:\n","        print(\"4. Significant interaction effects found:\")\n","        for term in significant_interactions:\n","            p_value = anova_result.loc[term, 'PR(>F)']\n","            print(f\"   - {term}: p = {p_value:.4f}\")\n","    else:\n","        print(\"4. No significant interaction effects found\")\n","\n","    # Dataset variability\n","    print(\"5. Dataset variability insights:\")\n","    dataset_means = df.groupby('Dataset')[response_var].mean().sort_values(ascending=False)\n","    dataset_vars = df.groupby('Dataset')[response_var].var().sort_values(ascending=False)\n","\n","    print(\"   - Dataset performance ranking:\")\n","    for dataset, mean in dataset_means.items():\n","        print(f\"     {dataset}: mean {response_var} = {mean:.4f}\")\n","\n","    print(\"   - Dataset variability ranking:\")\n","    for dataset, var in dataset_vars.items():\n","        print(f\"     {dataset}: variance = {var:.4f}\")\n","\n","    # Return all results\n","    results = {\n","        'lmm_result': lmm_result,\n","        'anova_result': anova_result,\n","        'post_hoc_results': post_hoc_results,\n","        'best_approaches': best_approaches,\n","        'figures': {\n","            'interaction_fig': interaction_fig,\n","            'dataset_fig': dataset_fig\n","        }\n","    }\n","\n","    return results\n","\n","# Run the analysis if script is executed directly\n","if __name__ == \"__main__\":\n","    file_path = \"data.csv\"  # Update this to your actual file path\n","    results = main(file_path)\n","    plt.show()  # Display all figures"],"metadata":{"id":"gpiwL9N-CeR7"},"execution_count":null,"outputs":[]}]}