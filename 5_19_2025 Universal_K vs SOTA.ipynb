{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMqhA588gOYnQdUBhQpCOGZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PFRKK6mCy-MM"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn.functional as F\n","import time\n","import pandas as pd\n","import os\n","import json\n","from datetime import datetime\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn.functional as F\n","from torch.multiprocessing import Process, Queue, set_start_method, Manager\n","from sklearn.decomposition import PCA, NMF, FastICA, KernelPCA, SparsePCA, FactorAnalysis\n","from sklearn.feature_selection import mutual_info_regression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import ElasticNet\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import DictionaryLearning\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.neighbors import NearestNeighbors\n","try:\n","    import umap\n","    UMAP_AVAILABLE = True\n","except ImportError:\n","    UMAP_AVAILABLE = False\n","    print(\"UMAP not available. UMAP initialization method will fall back to PCA.\")\n","import pandas as pd\n","import os\n","import time\n","import uuid\n","import warnings\n","from scipy.stats import entropy\n","from scipy.linalg import svd\n","import json\n","from datetime import datetime\n","\n","# Suppress warnings\n","warnings.filterwarnings('ignore')\n","\n","# Set random seeds\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","# ===== SETUP AND UTILITY FUNCTIONS =====\n","\n","def setup_device(gpu_id=None):\n","    \"\"\"Set up and return the appropriate device (GPU or CPU).\"\"\"\n","    if not torch.cuda.is_available():\n","        #print(\"CUDA not available. Using CPU.\")\n","        return torch.device('cpu')\n","\n","    num_gpus = torch.cuda.device_count()\n","    if num_gpus == 0:\n","        #print(\"No GPUs detected. Using CPU.\")\n","        return torch.device('cpu')\n","\n","    if gpu_id is not None:\n","        gpu_id = gpu_id % num_gpus\n","        device = torch.device(f'cuda:{gpu_id}')\n","        torch.cuda.set_device(device)\n","        print(f\"Using device: {device}\")\n","        return device\n","    else:\n","        device = torch.device('cuda:0')\n","        print(f\"Using default device: {device}\")\n","        return device\n","\n","def clean_gpu_memory(device=None):\n","    \"\"\"Clean GPU memory to avoid fragmentation.\"\"\"\n","    if device is not None and device.type == 'cuda':\n","        torch.cuda.empty_cache()\n","        torch.cuda.synchronize(device)\n","    elif torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","\n","def get_available_datasets():\n","    \"\"\"Check available datasets in the current directory.\"\"\"\n","    datasets = {}\n","    for prefix in ['fashion_mnist', 'mnist', 'diabetes', 'cifar10', 'dsprites', 'wine']:\n","        x_train_path = f'{prefix}_x_train.npy'\n","        if os.path.exists(x_train_path):\n","            try:\n","                x_sample = np.load(x_train_path, mmap_mode='r')\n","                datasets[prefix] = {'available': True, 'x_shape': x_sample.shape, 'x_path': x_train_path}\n","                print(f\"Dataset {prefix} available: {x_sample.shape[0]} samples, {x_sample.shape[1]} features\")\n","            except Exception as e:\n","                print(f\"Error loading {prefix}: {e}\")\n","                datasets[prefix] = {'available': False, 'error': str(e)}\n","        else:\n","            print(f\"Dataset {prefix} files not found\")\n","            datasets[prefix] = {'available': False, 'error': 'Files not found'}\n","    return datasets\n","\n","def sanitize_metrics(metrics):\n","    \"\"\"Ensure metrics have valid numerical values.\"\"\"\n","    sanitized = {}\n","    fallback_defaults = {\n","        'sparsity': 0.5,\n","        'modularity': 0.5,\n","        'factor_vae_score': 0.5,\n","        'sap_score': 0.5,\n","        'variance_ratio': 0.5,\n","        'mi_ksg': 0.5,\n","        'total_correlation': 0.5,\n","        'recon_error': 1.0\n","    }\n","\n","    for key, value in metrics.items():\n","        if isinstance(value, torch.Tensor):\n","            value = value.item()\n","\n","        if np.isnan(value) or np.isinf(value) or not (0 <= value <= 1):\n","            sanitized[key] = fallback_defaults.get(key, 0.5)\n","            print(f\"Warning: {key} invalid ({value}), using fallback: {sanitized[key]}\")\n","        else:\n","            sanitized[key] = value\n","    return sanitized\n","\n","def create_factor_analysis_k_matrix(x_data, num_factors, latent_dim, device):\n","    \"\"\"Initialize K matrix using Factor Analysis.\"\"\"\n","    try:\n","        # Move to CPU for sklearn\n","        x_np = x_data.cpu().numpy().reshape(x_data.shape[0], -1)\n","\n","        # Sample for efficiency\n","        if x_np.shape[0] > 10000:\n","            indices = np.random.choice(x_np.shape[0], 10000, replace=False)\n","            x_np = x_np[indices]\n","\n","        # Determine number of components\n","        total_components = min(num_factors * latent_dim, min(x_np.shape))\n","\n","        # Run Factor Analysis\n","        fa = FactorAnalysis(\n","            n_components=total_components,\n","            random_state=42\n","        )\n","        fa.fit(x_np)\n","\n","        # Create K matrices\n","        k_matrices = []\n","        for i in range(num_factors):\n","            # Extract components for this factor\n","            start_idx = i * latent_dim\n","            end_idx = min(start_idx + latent_dim, total_components)\n","\n","            if end_idx > start_idx:\n","                # Use Factor Analysis components\n","                k = torch.tensor(fa.components_[start_idx:end_idx].T, dtype=torch.float32)\n","            else:\n","                # If we run out of components, use random initialization\n","                k = torch.randn(x_np.shape[1], latent_dim)\n","\n","            # If we don't have enough components, pad with random values\n","            if k.shape[1] < latent_dim:\n","                padding = torch.randn(x_np.shape[1], latent_dim - k.shape[1])\n","                k = torch.cat([k, padding], dim=1)\n","\n","            # Normalize columns\n","            k = k / (torch.norm(k, dim=0, keepdim=True) + 1e-6)\n","            k_matrices.append(k)\n","\n","        # Stack and move to device\n","        result = torch.stack(k_matrices).to(device)\n","        return result\n","    except Exception as e:\n","        print(f\"FactorAnalysis initialization error: {e}\")\n","        return create_random_k_matrix(x_data, num_factors, latent_dim, device)\n","\n","\n","def create_pca_k_matrix(x_data, num_factors, latent_dim, device):\n","    \"\"\"Initialize K matrix using PCA.\"\"\"\n","    try:\n","        # Always move to CPU for sklearn operations\n","        x_np = x_data.cpu().numpy().reshape(x_data.shape[0], -1)\n","\n","        # Determine number of components\n","        total_components = min(num_factors * latent_dim, min(x_np.shape))\n","\n","        # Calculate PCA\n","        pca = PCA(n_components=total_components, random_state=42)\n","        pca.fit(x_np)\n","\n","        # Create K matrices\n","        k_matrices = []\n","        for i in range(num_factors):\n","            # Get components for this factor\n","            start_idx = i * latent_dim\n","            end_idx = min(start_idx + latent_dim, total_components)\n","\n","            if end_idx > start_idx:\n","                # Use PCA components\n","                k = torch.tensor(pca.components_[start_idx:end_idx].T, dtype=torch.float32)\n","            else:\n","                # If we run out of components, use random initialization\n","                k = torch.randn(x_np.shape[1], latent_dim)\n","\n","            # If we don't have enough components, pad with random values\n","            if k.shape[1] < latent_dim:\n","                padding = torch.randn(x_np.shape[1], latent_dim - k.shape[1])\n","                k = torch.cat([k, padding], dim=1)\n","\n","            # Normalize columns\n","            k = k / (torch.norm(k, dim=0, keepdim=True) + 1e-6)\n","            k_matrices.append(k)\n","\n","        # Stack and move to specified device\n","        result = torch.stack(k_matrices).to(device)\n","        return result\n","    except Exception as e:\n","        print(f\"PCA initialization error: {e}\")\n","        return create_random_k_matrix(x_data, num_factors, latent_dim, device)\n","\n","\n","def load_or_create_dataset(dataset_name, available_datasets):\n","    \"\"\"\n","    Load or create dataset with proper preprocessing.\n","\n","    Args:\n","        dataset_name: Name of the dataset\n","        available_datasets: Dictionary of available datasets\n","\n","    Returns:\n","        tuple of (x_data, y_data, is_classification)\n","    \"\"\"\n","    try:\n","        # Check if dataset is available\n","        if not available_datasets.get(dataset_name, {}).get('available', False):\n","            raise ValueError(f\"Dataset {dataset_name} is not available\")\n","\n","        # Load x_data\n","        x_path = available_datasets[dataset_name]['x_path']\n","        x_data = torch.tensor(np.load(x_path), dtype=torch.float32)\n","\n","        # Try to load y_data with common naming patterns\n","        y_patterns = [\n","            x_path.replace('_x_train', '_y_train'),\n","            x_path.replace('_x_', '_y_'),\n","            os.path.join(os.path.dirname(x_path), f'{dataset_name}_y_train.npy'),\n","            os.path.join(os.path.dirname(x_path), f'{dataset_name}_labels.npy')\n","        ]\n","\n","        y_data = None\n","        for y_path in y_patterns:\n","            if os.path.exists(y_path):\n","                try:\n","                    y_data = torch.tensor(np.load(y_path))\n","                    print(f\"Loaded labels from {y_path}\")\n","                    break\n","                except Exception as e:\n","                    print(f\"Error loading {y_path}: {e}\")\n","\n","        # If no labels found, create dummy values\n","        if y_data is None:\n","            print(f\"No labels found for {dataset_name}, creating dummy values\")\n","            y_data = torch.zeros(x_data.shape[0], 1)\n","\n","        # Determine if classification task\n","        is_classification = (y_data.dtype == torch.long or\n","                           (len(torch.unique(y_data)) < 100 and len(torch.unique(y_data)) > 1))\n","\n","        # Standardize data\n","        x_mean = x_mean = x_data.mean(dim=0, keepdim=True)\n","        x_std = x_data.std(dim=0, keepdim=True) + 1e-6\n","        x_data = (x_data - x_mean) / x_std\n","\n","        # Handle NaN or Inf values\n","        x_data = torch.nan_to_num(x_data, nan=0.0, posinf=0.0, neginf=0.0)\n","\n","        return x_data, y_data, is_classification\n","\n","    except Exception as e:\n","        print(f\"Error loading dataset {dataset_name}: {e}\")\n","        raise\n","\n","\n","def compare_universal_k_methods(results):\n","    \"\"\"\n","    Compare performance of Universal K method variations.\n","\n","    Args:\n","        results: Dictionary of results\n","\n","    Returns:\n","        DataFrame with comparisons\n","    \"\"\"\n","    comparison_rows = []\n","\n","    for dataset_name, dataset_results in results.items():\n","        # Check if k_methods exists and has results\n","        if 'k_methods' not in dataset_results or not dataset_results['k_methods']:\n","            continue\n","\n","        # For each factor count, find the best method\n","        for factors in [3, 5]:\n","            for dims in [8, 16]:\n","                factor_config = f\"f{factors}_d{dims}\"\n","\n","                # Find best method for this configuration\n","                best_score = -float('inf')\n","                best_method = None\n","\n","                for method_name, method_results in dataset_results['k_methods'].items():\n","                    for result in method_results:\n","                        if result['num_factors'] == factors and result['latent_dim'] == dims:\n","                            if result['combined_score'] > best_score:\n","                                best_score = result['combined_score']\n","                                best_method = method_name\n","\n","                # Add comparison row\n","                if best_method:\n","                    row = {\n","                        'dataset': dataset_name,\n","                        'factors': factors,\n","                        'dims': dims,\n","                        'config': factor_config,\n","                        'best_method': best_method,\n","                        'combined_score': best_score\n","                    }\n","\n","                    # Add per-method scores for this configuration\n","                    for method_name in dataset_results['k_methods'].keys():\n","                        method_score = -float('inf')\n","                        for result in dataset_results['k_methods'][method_name]:\n","                            if result['num_factors'] == factors and result['latent_dim'] == dims:\n","                                method_score = result['combined_score']\n","\n","                                # Also add individual metrics\n","                                for metric_name, metric_value in result['metrics'].items():\n","                                    row[f\"{method_name}_{metric_name}\"] = metric_value\n","\n","                        row[f\"{method_name}_score\"] = method_score\n","\n","                    comparison_rows.append(row)\n","\n","    # Create DataFrame\n","    if comparison_rows:\n","        comparison_df = pd.DataFrame(comparison_rows)\n","        return comparison_df\n","    else:\n","        # Return empty DataFrame with columns\n","        return pd.DataFrame(columns=['dataset', 'factors', 'dims', 'config',\n","                                   'best_method', 'combined_score'])\n","\n","def evaluate_k_matrix(x_data, k_matrix, num_factors, latent_dim, device):\n","    \"\"\"Evaluate K matrix with comprehensive metrics.\"\"\"\n","    try:\n","        # Ensure consistent device placement\n","        x_data = x_data.to(device)\n","        k_matrix = k_matrix.to(device)\n","\n","        # Initialize metrics dictionary\n","        metrics = {\n","            'recon_error': 1.0,\n","            'mi_ksg': 0.5,\n","            'sparsity': 0.5,\n","            'total_correlation': 0.5,\n","            'modularity': 0.5,\n","            'factor_vae_score': 0.5,\n","            'sap_score': 0.5,\n","            'variance_ratio': 0.5\n","        }\n","\n","        # Special case for num_factors=1\n","        if num_factors <= 1:\n","            print(\"Evaluation: Single factor case, special handling\")\n","            metrics['total_correlation'] = 0.0  # No correlation with self\n","            metrics['mi_ksg'] = 0.0  # No mutual information with self\n","            metrics['modularity'] = 1.0  # Fully modular with self\n","\n","        # Check for NaNs or Infs in input\n","        if torch.isnan(k_matrix).any() or torch.isinf(k_matrix).any():\n","            print(\"Evaluation Debug: K matrix contains NaN or Inf values!\")\n","            k_matrix = torch.nan_to_num(k_matrix, nan=0.0, posinf=1.0, neginf=-1.0)\n","\n","        # Normalize k_matrix\n","        k_norm = torch.norm(k_matrix.view(num_factors, -1, latent_dim), dim=1, keepdim=True)\n","        k_matrix = k_matrix / (k_norm + 1e-8)\n","\n","        # Encode data\n","        z = encode_data(x_data, k_matrix)\n","\n","        # Reconstruction\n","        batch_size = 1024\n","        all_recon = []\n","\n","        with torch.no_grad():\n","            for i in range(0, len(x_data), batch_size):\n","                batch_x = x_data[i:i + batch_size]\n","                batch_indices = slice(i, min(i + batch_size, len(x_data)))\n","                batch_z = z[batch_indices]\n","\n","                # Reconstruct incrementally\n","                batch_recon = torch.zeros_like(batch_x)\n","\n","                for j in range(num_factors):\n","                    # Get the z values for this factor\n","                    z_j = batch_z[:, j]\n","                    # Add the reconstruction for this factor\n","                    batch_recon += torch.matmul(z_j, k_matrix[j].T)\n","\n","                all_recon.append(batch_recon)\n","\n","        # Concatenate all batches\n","        reconstructed = torch.cat(all_recon, dim=0)\n","\n","        # Calculate reconstruction error\n","        recon_error = F.mse_loss(reconstructed, x_data)\n","        data_var = torch.var(x_data)\n","        metrics['recon_error'] = min(1.0, recon_error.item() / (data_var.item() + 1e-8))\n","\n","        # Sample a subset for metric computation\n","        sample_size = min(2000, z.shape[0])\n","        sample_indices = torch.randperm(z.shape[0], device=device)[:sample_size]\n","        z_sampled = z[sample_indices]\n","        x_sampled = x_data[sample_indices]\n","\n","        # If single factor, just compute remaining metrics\n","        if num_factors <= 1:\n","            metrics['sparsity'] = sparsity_score(k_matrix).item()\n","\n","            try:\n","                # Move to CPU for SVD\n","                x_flat = x_sampled.reshape(sample_size, -1).detach().cpu().numpy()\n","                z_flat = z_sampled.reshape(sample_size, -1).detach().cpu().numpy()\n","\n","                # Handle NaNs\n","                if np.isnan(x_flat).any() or np.isinf(x_flat).any():\n","                    x_flat = np.nan_to_num(x_flat, nan=0.0)\n","                if np.isnan(z_flat).any() or np.isinf(z_flat).any():\n","                    z_flat = np.nan_to_num(z_flat, nan=0.0)\n","\n","                # Add noise for stability\n","                x_flat = x_flat + 1e-8 * np.random.randn(*x_flat.shape)\n","                z_flat = z_flat + 1e-8 * np.random.randn(*z_flat.shape)\n","\n","                # Compute SVD for data\n","                u_x, s_x, vt_x = svd(x_flat, full_matrices=False)\n","                total_variance_x = np.sum(s_x ** 2)\n","\n","                # Compute SVD for latent\n","                u_z, s_z, vt_z = svd(z_flat, full_matrices=False)\n","                total_variance_z = np.sum(s_z ** 2)\n","\n","                # Variance ratio\n","                metrics['variance_ratio'] = min(0.95, total_variance_z / (total_variance_x + 1e-6))\n","            except Exception as e:\n","                print(f\"Variance ratio calculation error: {e}\")\n","                metrics['variance_ratio'] = 0.5\n","\n","            return sanitize_metrics(metrics)\n","\n","        # For multi-factor case, compute all metrics\n","        try:\n","            # Compute mutual information between factors using KSG estimator\n","            # Move to CPU for KSG computation\n","            z_cpu = z_sampled.detach().cpu()\n","            mi_scores = []\n","\n","            for i in range(num_factors):\n","                for j in range(i + 1, num_factors):\n","                    # Take the first dimension of each factor for simplicity\n","                    mi_scores.append(safe_mi_ksg_estimator(\n","                        z_cpu[:, i, 0].flatten(),\n","                        z_cpu[:, j, 0].flatten()\n","                    ))\n","\n","            metrics['mi_ksg'] = np.mean(mi_scores) if mi_scores else 0.5\n","        except Exception as e:\n","            print(f\"MI KSG calculation error: {e}\")\n","            metrics['mi_ksg'] = 0.5\n","\n","        try:\n","            # Compute sparsity\n","            metrics['sparsity'] = sparsity_score(k_matrix).item()\n","        except Exception as e:\n","            print(f\"Sparsity calculation error: {e}\")\n","            metrics['sparsity'] = 0.5\n","\n","        try:\n","            # Compute total correlation\n","            tc_result = robust_total_correlation(z_sampled, num_factors, latent_dim)\n","            metrics['total_correlation'] = tc_result.item() if isinstance(tc_result, torch.Tensor) else tc_result\n","        except Exception as e:\n","            print(f\"Total correlation calculation error: {e}\")\n","            metrics['total_correlation'] = 0.5\n","\n","        try:\n","            # Compute modularity\n","            mod_result = robust_modularity_score(z_sampled, num_factors, latent_dim)\n","            metrics['modularity'] = mod_result.item() if isinstance(mod_result, torch.Tensor) else mod_result\n","        except Exception as e:\n","            print(f\"Modularity calculation error: {e}\")\n","            metrics['modularity'] = 0.5\n","\n","        try:\n","            # Compute FactorVAE score (needs CPU)\n","            z_cpu = z_sampled.detach().cpu()\n","            metrics['factor_vae_score'] = robust_factor_vae_score(z_cpu, num_factors, latent_dim)\n","        except Exception as e:\n","            print(f\"FactorVAE score calculation error: {e}\")\n","            metrics['factor_vae_score'] = 0.5\n","\n","        try:\n","            # Compute SAP score (needs CPU)\n","            z_cpu = z_sampled.detach().cpu()\n","            x_cpu = x_sampled.detach().cpu()\n","            metrics['sap_score'] = robust_sap_score(z_cpu, x_cpu, num_factors, latent_dim)\n","        except Exception as e:\n","            print(f\"SAP score calculation error: {e}\")\n","            metrics['sap_score'] = 0.5\n","\n","        try:\n","            # Compute variance ratio\n","            x_flat = x_sampled.reshape(sample_size, -1).detach().cpu().numpy()\n","            z_flat = z_sampled.reshape(sample_size, -1).detach().cpu().numpy()\n","\n","            # Handle NaNs\n","            if np.isnan(x_flat).any() or np.isinf(x_flat).any():\n","                x_flat = np.nan_to_num(x_flat, nan=0.0)\n","            if np.isnan(z_flat).any() or np.isinf(z_flat).any():\n","                z_flat = np.nan_to_num(z_flat, nan=0.0)\n","\n","            # Add noise for stability\n","            x_flat = x_flat + 1e-8 * np.random.randn(*x_flat.shape)\n","            z_flat = z_flat + 1e-8 * np.random.randn(*z_flat.shape)\n","\n","            # Compute SVD\n","            u_x, s_x, vt_x = svd(x_flat, full_matrices=False)\n","            total_variance_x = np.sum(s_x ** 2)\n","\n","            u_z, s_z, vt_z = svd(z_flat, full_matrices=False)\n","            total_variance_z = np.sum(s_z ** 2)\n","\n","            metrics['variance_ratio'] = min(0.95, total_variance_z / (total_variance_x + 1e-6))\n","        except Exception as e:\n","            print(f\"Variance ratio calculation error: {e}\")\n","            metrics['variance_ratio'] = 0.5\n","\n","        return sanitize_metrics(metrics)\n","\n","    except Exception as e:\n","        print(f\"Evaluation error: {e}\")\n","        return sanitize_metrics(metrics)\n","\n","\n","\n","# ===== MODEL IMPLEMENTATIONS =====\n","\n","class VIB(nn.Module):\n","    \"\"\"Variational Information Bottleneck Autoencoder.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, latent_dim, beta=1.0):\n","        super(VIB, self).__init__()\n","\n","        self.beta = beta\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2)\n","        )\n","\n","        # Latent parameters\n","        self.mu = nn.Linear(hidden_dim // 2, latent_dim)\n","        self.log_var = nn.Linear(hidden_dim // 2, latent_dim)\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, input_dim)\n","        )\n","\n","        # Task predictor\n","        self.predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, 1)  # For regression, will be adjusted for classification\n","        )\n","\n","    def encode(self, x):\n","        h = self.encoder(x)\n","        return self.mu(h), self.log_var(h)\n","\n","    def reparameterize(self, mu, log_var):\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def predict(self, z):\n","        return self.predictor(z)\n","\n","    def forward(self, x):\n","        mu, log_var = self.encode(x)\n","        z = self.reparameterize(mu, log_var)\n","        x_recon = self.decode(z)\n","        pred = self.predict(z)\n","        return x_recon, mu, log_var, z, pred\n","\n","    def loss_function(self, x, x_recon, mu, log_var, y, pred):\n","        # Reconstruction loss\n","        recon_loss = F.mse_loss(x_recon, x)\n","\n","        # KL divergence\n","        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","\n","        # Task loss (MSE for regression, will be adjusted for classification)\n","        task_loss = F.mse_loss(pred, y)\n","\n","        # Total loss\n","        total_loss = task_loss + self.beta * kl_loss + recon_loss\n","\n","        return total_loss, recon_loss, kl_loss, task_loss\n","\n","\n","class BetaVAE(nn.Module):\n","    \"\"\"Beta-VAE for disentangled representation learning.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, latent_dim, beta=1.0):\n","        super(BetaVAE, self).__init__()\n","\n","        self.beta = beta\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2)\n","        )\n","\n","        # Latent parameters\n","        self.mu = nn.Linear(hidden_dim // 2, latent_dim)\n","        self.log_var = nn.Linear(hidden_dim // 2, latent_dim)\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, input_dim)\n","        )\n","\n","        # Task predictor\n","        self.predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, 1)  # For regression, will be adjusted for classification\n","        )\n","\n","    def encode(self, x):\n","        h = self.encoder(x)\n","        return self.mu(h), self.log_var(h)\n","\n","    def reparameterize(self, mu, log_var):\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def predict(self, z):\n","        return self.predictor(z)\n","\n","    def forward(self, x):\n","        mu, log_var = self.encode(x)\n","        z = self.reparameterize(mu, log_var)\n","        x_recon = self.decode(z)\n","        pred = self.predict(z)\n","        return x_recon, mu, log_var, z, pred\n","\n","    def loss_function(self, x, x_recon, mu, log_var, y, pred):\n","        # Reconstruction loss\n","        recon_loss = F.mse_loss(x_recon, x)\n","\n","        # KL divergence with beta scaling\n","        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","\n","        # Task loss\n","        task_loss = F.mse_loss(pred, y)\n","\n","        # Total loss with beta weighting\n","        total_loss = task_loss + self.beta * kl_loss + recon_loss\n","\n","        return total_loss, recon_loss, kl_loss, task_loss\n","\n","\n","class DropoutRegularizedModel(nn.Module):\n","    \"\"\"Neural network with dropout and weight decay for regularization.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.5):\n","        super(DropoutRegularizedModel, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_dim // 2, output_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","class SparseAutoencoder(nn.Module):\n","    \"\"\"Autoencoder with L1 sparsity regularization.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, latent_dim, sparsity_weight=0.01):\n","        super(SparseAutoencoder, self).__init__()\n","\n","        self.sparsity_weight = sparsity_weight\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, latent_dim)\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, input_dim)\n","        )\n","\n","        # Task predictor\n","        self.predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, 1)  # For regression, will be adjusted for classification\n","        )\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        x_recon = self.decoder(z)\n","        pred = self.predictor(z)\n","        return x_recon, z, pred\n","\n","    def loss_function(self, x, x_recon, z, y, pred):\n","        # Reconstruction loss\n","        recon_loss = F.mse_loss(x_recon, x)\n","\n","        # L1 sparsity regularization\n","        sparsity_loss = torch.mean(torch.abs(z))\n","\n","        # Task loss\n","        task_loss = F.mse_loss(pred, y)\n","\n","        # Total loss\n","        total_loss = task_loss + recon_loss + self.sparsity_weight * sparsity_loss\n","\n","        return total_loss, recon_loss, sparsity_loss, task_loss\n","\n","\n","# ===== DISTILLATION METHODS =====\n","\n","def knowledge_distillation_loss(student_logits, teacher_logits, y_true, temperature=4.0, alpha=0.5):\n","    \"\"\"\n","    Compute the knowledge distillation loss.\n","\n","    Args:\n","        student_logits: Logits from the student model\n","        teacher_logits: Logits from the teacher model\n","        y_true: Ground truth labels\n","        temperature: Softmax temperature for distillation\n","        alpha: Weight for distillation loss vs. task loss\n","\n","    Returns:\n","        The combined loss\n","    \"\"\"\n","    # For classification tasks\n","    if len(y_true.shape) == 1:  # Labels are indices\n","        # Task loss\n","        task_loss = F.cross_entropy(student_logits, y_true)\n","\n","        # Distillation loss\n","        # Scale logits by temperature and compute soft targets\n","        soft_targets = F.softmax(teacher_logits / temperature, dim=1)\n","        log_probs = F.log_softmax(student_logits / temperature, dim=1)\n","        distillation_loss = -(soft_targets * log_probs).sum(dim=1).mean() * (temperature ** 2)\n","\n","        # Combined loss\n","        loss = alpha * distillation_loss + (1 - alpha) * task_loss\n","\n","    # For regression tasks\n","    else:\n","        # Task loss\n","        task_loss = F.mse_loss(student_logits, y_true)\n","\n","        # Distillation loss - MSE between student and teacher outputs\n","        distillation_loss = F.mse_loss(student_logits, teacher_logits)\n","\n","        # Combined loss\n","        loss = alpha * distillation_loss + (1 - alpha) * task_loss\n","\n","    return loss\n","\n","def attention_transfer_loss(student_features, teacher_features, y_true, model_output, beta=0.5):\n","    \"\"\"\n","    Compute the attention transfer loss.\n","\n","    Args:\n","        student_features: List of feature maps from student model\n","        teacher_features: List of feature maps from teacher model\n","        y_true: Ground truth labels\n","        model_output: Output from the student model\n","        beta: Weight for attention loss vs. task loss\n","\n","    Returns:\n","        The combined loss\n","    \"\"\"\n","    # Task loss (classification or regression)\n","    if len(y_true.shape) == 1:  # Classification with class indices\n","        task_loss = F.cross_entropy(model_output, y_true)\n","    else:  # Regression\n","        task_loss = F.mse_loss(model_output, y_true)\n","\n","    # Attention transfer loss\n","    attention_loss = 0.0\n","    for student_feat, teacher_feat in zip(student_features, teacher_features):\n","        # Compute normalized attention maps\n","        student_attention = F.normalize(student_feat.pow(2).mean(1).view(student_feat.size(0), -1), p=2, dim=1)\n","        teacher_attention = F.normalize(teacher_feat.pow(2).mean(1).view(teacher_feat.size(0), -1), p=2, dim=1)\n","\n","        # L2 distance between attention maps\n","        attention_loss += F.mse_loss(student_attention, teacher_attention)\n","\n","    # Combined loss\n","    loss = task_loss + beta * attention_loss\n","\n","    return loss\n","\n","\n","# ===== EVALUATION FUNCTIONS =====\n","\n","def evaluate_model_metrics(model, dataloader, device, is_classification=True):\n","    \"\"\"\n","    Evaluate a model and return comprehensive metrics.\n","\n","    Args:\n","        model: The trained model to evaluate\n","        dataloader: DataLoader for evaluation data\n","        device: Device to run evaluation on\n","        is_classification: Whether this is a classification task\n","\n","    Returns:\n","        Dictionary of metrics\n","    \"\"\"\n","    model.eval()\n","    all_targets = []\n","    all_predictions = []\n","    all_probs = []  # For AUC calculation in classification\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            x, y = batch\n","            x, y = x.to(device), y.to(device)\n","\n","            # Forward pass depends on model type\n","            if isinstance(model, (VIB, BetaVAE)):\n","                _, _, _, _, pred = model(x)\n","            elif isinstance(model, SparseAutoencoder):\n","                _, _, pred = model(x)\n","            else:  # Standard models like DropoutRegularizedModel\n","                pred = model(x)\n","\n","            # Store predictions and targets\n","            if is_classification:\n","                probs = F.softmax(pred, dim=1) if pred.size(1) > 1 else torch.sigmoid(pred)\n","                _, predicted = torch.max(pred, 1) if pred.size(1) > 1 else (pred > 0.5).long()\n","                all_probs.append(probs.cpu())\n","                all_predictions.append(predicted.cpu())\n","                all_targets.append(y.cpu())\n","            else:\n","                all_predictions.append(pred.cpu())\n","                all_targets.append(y.cpu())\n","\n","    # Concatenate results\n","    if is_classification:\n","        all_targets = torch.cat(all_targets).numpy()\n","        all_predictions = torch.cat(all_predictions).numpy()\n","        all_probs = torch.cat(all_probs).numpy()\n","\n","        # Calculate classification metrics\n","        accuracy = (all_predictions == all_targets).mean()\n","\n","        # For multi-class, calculate macro averages\n","        precision = precision_score(all_targets, all_predictions, average='macro', zero_division=0)\n","        recall = recall_score(all_targets, all_predictions, average='macro', zero_division=0)\n","        f1 = f1_score(all_targets, all_predictions, average='macro', zero_division=0)\n","\n","        # AUC calculation (handle multi-class)\n","        if all_probs.shape[1] > 2:  # Multi-class\n","            # One-hot encode targets for multi-class AUC\n","            from sklearn.preprocessing import label_binarize\n","            classes = list(range(all_probs.shape[1]))\n","            all_targets_binary = label_binarize(all_targets, classes=classes)\n","            auc = roc_auc_score(all_targets_binary, all_probs, multi_class='ovr')\n","        else:  # Binary classification\n","            auc = roc_auc_score(all_targets, all_probs[:, 1] if all_probs.shape[1] > 1 else all_probs)\n","\n","        return {\n","            'accuracy': accuracy,\n","            'precision': precision,\n","            'recall': recall,\n","            'f1_score': f1,\n","            'auc': auc\n","        }\n","    else:\n","        all_targets = torch.cat(all_targets).numpy()\n","        all_predictions = torch.cat(all_predictions).numpy()\n","\n","        # Calculate regression metrics\n","        mse = mean_squared_error(all_targets, all_predictions)\n","        mae = mean_absolute_error(all_targets, all_predictions)\n","        r2 = r2_score(all_targets, all_predictions)\n","\n","        return {\n","            'mse': mse,\n","            'mae': mae,\n","            'rmse': np.sqrt(mse),\n","            'r2_score': r2\n","        }\n","\n","\n","def evaluate_baseline_method(method_name, model, test_loader, device, is_classification=True, k_matrix=None, num_factors=None, latent_dim=None):\n","    \"\"\"\n","    Evaluate a baseline method and compute comprehensive metrics.\n","\n","    Args:\n","        method_name: Name of the method being evaluated\n","        model: The trained model to evaluate\n","        test_loader: DataLoader for test data\n","        device: Device to run evaluation on\n","        is_classification: Whether this is a classification task\n","        k_matrix: Optional K matrix for universal K methods\n","        num_factors: Number of factors for universal K methods\n","        latent_dim: Latent dimension per factor\n","\n","    Returns:\n","        Dictionary of metrics\n","    \"\"\"\n","    task_metrics = evaluate_model_metrics(model, test_loader, device, is_classification)\n","\n","    # Add method-specific metrics\n","    metrics = {\n","        'method': method_name,\n","        'task_metrics': task_metrics\n","    }\n","\n","    # For autoencoder-based methods, add reconstruction metrics\n","    if isinstance(model, (VIB, BetaVAE, SparseAutoencoder)):\n","        model.eval()\n","        recon_loss = 0.0\n","\n","        with torch.no_grad():\n","            for batch in test_loader:\n","                x, y = batch\n","                x, y = x.to(device), y.to(device)\n","\n","                if isinstance(model, (VIB, BetaVAE)):\n","                    x_recon, mu, log_var, z, _ = model(x)\n","                    recon_error = F.mse_loss(x_recon, x).item()\n","\n","                    # Add KL divergence for VIB/VAE models\n","                    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()).item()\n","                    metrics['kl_divergence'] = kl_div / len(test_loader)\n","\n","                    # Add disentanglement metrics if applicable\n","                    if num_factors is not None and latent_dim is not None:\n","                        try:\n","                            z_reshaped = z.view(-1, num_factors, latent_dim)\n","                            metrics['disentanglement'] = {\n","                                'mi_ksg': safe_mi_ksg_estimator(z_reshaped),\n","                                'total_correlation': robust_total_correlation(z_reshaped),\n","                                'modularity': robust_modularity_score(z_reshaped),\n","                                'factor_vae_score': robust_factor_vae_score(z_reshaped),\n","                                'sap_score': robust_sap_score(z_reshaped, x)\n","                            }\n","                        except Exception as e:\n","                            print(f\"Error calculating disentanglement metrics: {e}\")\n","\n","                elif isinstance(model, SparseAutoencoder):\n","                    x_recon, z, _ = model(x)\n","                    recon_error = F.mse_loss(x_recon, x).item()\n","\n","                    # Add sparsity measure\n","                    sparsity = torch.mean(torch.abs(z)).item()\n","                    metrics['sparsity'] = sparsity\n","\n","                recon_loss += recon_error\n","\n","        metrics['recon_error'] = recon_loss / len(test_loader)\n","\n","    # For K-matrix methods, use the evaluate_k_matrix function if provided\n","    if k_matrix is not None and 'Universal_K' in method_name:\n","        try:\n","            k_metrics = evaluate_k_matrix(next(iter(test_loader))[0].to(device), k_matrix, num_factors, latent_dim, device)\n","            metrics['k_metrics'] = k_metrics\n","        except Exception as e:\n","            print(f\"Error evaluating K matrix metrics: {e}\")\n","\n","    return metrics\n","\n","\n","def train_model(model, train_loader, val_loader, device, is_classification=True, epochs=50, patience=5):\n","    \"\"\"\n","    Train a model with early stopping.\n","\n","    Args:\n","        model: The model to train\n","        train_loader: DataLoader for training data\n","        val_loader: DataLoader for validation data\n","        device: Device to run training on\n","        is_classification: Whether this is a classification task\n","        epochs: Maximum number of epochs to train\n","        patience: Number of epochs to wait for improvement before stopping\n","\n","    Returns:\n","        Trained model\n","    \"\"\"\n","    # Set up optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Set up criterion for task loss\n","    if is_classification:\n","        task_criterion = nn.CrossEntropyLoss()\n","    else:\n","        task_criterion = nn.MSELoss()\n","\n","    # Train for specified epochs with early stopping\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        for batch_x, batch_y in train_loader:\n","            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass depends on model type\n","            if isinstance(model, VIB):\n","                x_recon, mu, log_var, z, pred = model(batch_x)\n","                loss, _, _, _ = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","            elif isinstance(model, BetaVAE):\n","                x_recon, mu, log_var, z, pred = model(batch_x)\n","                loss, _, _, _ = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","            elif isinstance(model, SparseAutoencoder):\n","                x_recon, z, pred = model(batch_x)\n","                loss, _, _, _ = model.loss_function(batch_x, x_recon, z, batch_y, pred)\n","            else:  # Standard models like DropoutRegularizedModel\n","                pred = model(batch_x)\n","                loss = task_criterion(pred, batch_y)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for batch_x, batch_y in val_loader:\n","                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","\n","                # Forward pass depends on model type\n","                if isinstance(model, VIB):\n","                    x_recon, mu, log_var, z, pred = model(batch_x)\n","                    _, _, _, task_loss = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","                elif isinstance(model, BetaVAE):\n","                    x_recon, mu, log_var, z, pred = model(batch_x)\n","                    _, _, _, task_loss = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","                elif isinstance(model, SparseAutoencoder):\n","                    x_recon, z, pred = model(batch_x)\n","                    _, _, _, task_loss = model.loss_function(batch_x, x_recon, z, batch_y, pred)\n","                else:  # Standard models\n","                    pred = model(batch_x)\n","                    task_loss = task_criterion(pred, batch_y)\n","\n","                val_loss += task_loss.item()\n","\n","        val_loss /= len(val_loader)\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= patience:\n","                print(f\"Early stopping at epoch {epoch}\")\n","                break\n","\n","    return model\n","\n","\n","def refine_k_matrix(x_data, k_matrix, num_factors, latent_dim, device, epochs=100):\n","    \"\"\"Refine K matrix with robust optimization.\"\"\"\n","    try:\n","        #print(f\"Refining K matrix on {device}...\")\n","\n","        # Make a copy for training and ensure it's on the correct device\n","        k_matrix = k_matrix.clone().to(device).requires_grad_(True)\n","\n","        # Setup optimizer with conservative learning rate\n","        optimizer = optim.Adam([k_matrix], lr=5e-5, weight_decay=1e-6)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=20)\n","\n","        # Setup data loading\n","        batch_size = min(1024, len(x_data))\n","        dataset = TensorDataset(x_data)\n","        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","\n","        # Track best matrix seen so far\n","        best_k_matrix = k_matrix.clone().detach()\n","        best_loss = float('inf')\n","        patience, patience_counter = 30, 0\n","\n","        for epoch in range(epochs):\n","            recon_loss_epoch = 0.0\n","            tc_loss_epoch = 0.0\n","            ortho_loss_epoch = 0.0\n","            batches_processed = 0\n","\n","            for batch in loader:\n","                x = batch[0].to(device, non_blocking=True)\n","                optimizer.zero_grad()\n","\n","                # Check input shape\n","                if x.dim() == 1:  # If 1D tensor, reshape to 2D\n","                    x = x.unsqueeze(0)\n","\n","                # Reshape k_matrix for computation\n","                try:\n","                    k_reshaped = k_matrix.view(num_factors, -1, latent_dim)\n","                except RuntimeError as e:\n","                    #print(f\"Refinement error: shape issue with k_matrix: {e}\")\n","                    #print(f\"k_matrix shape: {k_matrix.shape}, num_factors: {num_factors}, latent_dim: {latent_dim}\")\n","                    return k_matrix.detach()\n","\n","                # Compute latent representations\n","                z_factors = []\n","                for j in range(num_factors):\n","                    try:\n","                        z_factor = torch.matmul(x, k_reshaped[j])\n","                        z_factors.append(z_factor)\n","                    except RuntimeError as e:\n","                        #print(f\"Error in factor {j} computation: {e}\")\n","                        #print(f\"x shape: {x.shape}, k_reshaped[{j}] shape: {k_reshaped[j].shape}\")\n","                        return k_matrix.detach()\n","\n","                z = torch.stack(z_factors, dim=1)\n","\n","                # Compute reconstruction\n","                recon = torch.zeros_like(x)\n","                for j in range(num_factors):\n","                    recon += torch.matmul(z_factors[j], k_reshaped[j].T)\n","\n","                # Basic reconstruction loss\n","                recon_loss = F.mse_loss(recon, x)\n","\n","                # Additional losses for better disentanglement\n","\n","                # Variance penalty - encourage each latent dimension to have variance\n","                z_var = torch.var(z, dim=0).mean()\n","                variance_penalty = 0.1 * torch.clamp(1.0 - z_var, min=0.0)\n","\n","                # Sparsity loss - encourage sparse k_matrix\n","                sparsity_loss = 0.01 * torch.mean(torch.abs(k_matrix))\n","\n","                # Orthogonality loss - encourage factors to be orthogonal\n","                ortho_loss = 0.0\n","                for i in range(num_factors):\n","                    for j in range(i + 1, num_factors):\n","                        ortho_loss += torch.norm(torch.mm(k_reshaped[i].t(), k_reshaped[j]))\n","                ortho_loss = 0.01 * ortho_loss\n","\n","                # Total correlation loss - encourage independence within factors\n","                tc_loss = 0.0\n","                z_reshaped = z.view(-1, num_factors, latent_dim)\n","\n","                for i in range(num_factors):\n","                    # Calculate correlation matrix for each factor's dimensions\n","                    z_factor = z_reshaped[:, i, :]\n","                    z_centered = z_factor - z_factor.mean(0, keepdim=True)\n","                    cov = torch.mm(z_centered.t(), z_centered) / (z_centered.shape[0] - 1)\n","                    # Normalize to get correlation\n","                    var = torch.diag(cov).view(-1, 1)\n","                    corr = cov / torch.sqrt(var * var.t() + 1e-8)\n","                    # Sum absolute off-diagonal elements\n","                    tc_loss += torch.sum(torch.abs(corr * (1 - torch.eye(latent_dim, device=device))))\n","\n","                tc_loss = 0.01 * tc_loss\n","\n","                # Modularity loss - encourage between-factor independence\n","                modularity_loss = 0.0\n","                for i in range(num_factors):\n","                    for j in range(i + 1, num_factors):\n","                        z_i = z_reshaped[:, i, :]\n","                        z_j = z_reshaped[:, j, :]\n","                        z_i_centered = z_i - z_i.mean(0, keepdim=True)\n","                        z_j_centered = z_j - z_j.mean(0, keepdim=True)\n","                        cross_corr = torch.mm(z_i_centered.t(), z_j_centered) / (z_i_centered.shape[0] - 1)\n","                        modularity_loss += torch.norm(cross_corr)\n","\n","                modularity_loss = 0.01 * modularity_loss\n","\n","                # Total loss\n","                total_loss = (3.0 * recon_loss +\n","                             variance_penalty +\n","                             sparsity_loss +\n","                             ortho_loss +\n","                             tc_loss +\n","                             modularity_loss)\n","\n","                # Check for numerical stability\n","                if torch.isnan(total_loss) or torch.isinf(total_loss):\n","                    print(f\"NaN or Inf loss detected at epoch {epoch}, batch {batches_processed}\")\n","                    continue\n","\n","                # Backward and optimize\n","                total_loss.backward()\n","                torch.nn.utils.clip_grad_norm_([k_matrix], max_norm=1.0)\n","                optimizer.step()\n","\n","                # Track metrics\n","                recon_loss_epoch += recon_loss.item()\n","                tc_loss_epoch += tc_loss.item() if isinstance(tc_loss, torch.Tensor) else tc_loss\n","                ortho_loss_epoch += ortho_loss.item() if isinstance(ortho_loss, torch.Tensor) else ortho_loss\n","                batches_processed += 1\n","\n","                # Clean up to prevent memory fragmentation\n","                del x, z, z_factors, recon\n","                clean_gpu_memory(device)\n","\n","            # Average losses\n","            if batches_processed > 0:\n","                recon_loss_epoch /= batches_processed\n","                tc_loss_epoch /= batches_processed\n","                ortho_loss_epoch /= batches_processed\n","\n","                # Update learning rate\n","                scheduler.step(recon_loss_epoch)\n","\n","                # Track best model\n","                if recon_loss_epoch < best_loss:\n","                    best_loss = recon_loss_epoch\n","                    best_k_matrix = k_matrix.clone().detach()\n","                    patience_counter = 0\n","                    #print(f\"Epoch {epoch}: New best loss: {best_loss:.6f}\")\n","                else:\n","                    patience_counter += 1\n","                    if patience_counter >= patience:\n","                        #print(f\"Early stopping at epoch {epoch}\")\n","                        break\n","\n","\n","        # Normalize the best matrix\n","        k_norm = torch.norm(best_k_matrix.view(num_factors, -1, latent_dim), dim=1, keepdim=True)\n","        k_matrix_normalized = best_k_matrix / (k_norm + 1e-6)\n","\n","        # Clean up\n","        clean_gpu_memory(device)\n","\n","        return k_matrix_normalized.detach()\n","\n","    except Exception as e:\n","        #print(f\"Refinement error: {e}\")\n","        # Return the original matrix as fallback\n","        return k_matrix.detach()\n","\n","def encode_data(x_data, k_matrix):\n","    \"\"\"Encode data with k_matrix.\"\"\"\n","    device = x_data.device\n","\n","    # Ensure k_matrix is on the same device as x_data\n","    if k_matrix.device != device:\n","        k_matrix = k_matrix.to(device)\n","\n","    num_factors = k_matrix.shape[0]\n","    batch_size = 1024\n","    all_z = []\n","\n","    with torch.no_grad():\n","        for i in range(0, len(x_data), batch_size):\n","            batch_x = x_data[i:i + batch_size]\n","\n","            # Process each factor separately for memory efficiency\n","            batch_z_factors = []\n","            for j in range(num_factors):\n","                z_factor = torch.matmul(batch_x, k_matrix[j])\n","                batch_z_factors.append(z_factor)\n","\n","            batch_z = torch.stack(batch_z_factors, dim=1)\n","            all_z.append(batch_z)\n","\n","    # Concatenate all batches\n","    z = torch.cat(all_z, dim=0)\n","    return z\n","\n","\n","def create_clustered_k_matrix(x_data, num_factors, latent_dim, device):\n","    \"\"\"Initialize K matrix using feature clustering.\"\"\"\n","    try:\n","        # Move to CPU for sklearn\n","        x_np = x_data.cpu().numpy().reshape(x_data.shape[0], -1)\n","\n","        # Sample for efficiency\n","        if x_np.shape[0] > 10000:\n","            indices = np.random.choice(x_np.shape[0], 10000, replace=False)\n","            x_np = x_np[indices]\n","\n","        # Calculate correlation matrix\n","        corr_matrix = np.corrcoef(x_np.T)\n","        dist_matrix = 1 - np.abs(np.nan_to_num(corr_matrix))\n","\n","        # Determine number of clusters\n","        n_clusters = min(num_factors, x_np.shape[1])\n","\n","        # Run KMeans\n","        clustering = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n","        cluster_labels = clustering.fit_predict(dist_matrix)\n","\n","        # Create K matrices\n","        k_matrices = []\n","        for i in range(num_factors):\n","            # Get indices for this cluster\n","            if i < n_clusters:\n","                cluster_indices = np.where(cluster_labels == i)[0]\n","            else:\n","                cluster_indices = np.array([])\n","\n","            # Initialize k matrix\n","            k = torch.zeros(x_np.shape[1], latent_dim)\n","\n","            if len(cluster_indices) > 0:\n","                # Set values for features in this cluster\n","                for j in range(latent_dim):\n","                    # Select a subset of the cluster features for each latent dimension\n","                    indices = cluster_indices[np.random.choice(\n","                        len(cluster_indices),\n","                        max(1, len(cluster_indices) // latent_dim),\n","                        replace=False\n","                    )]\n","                    k[indices, j] = 1.0\n","\n","                # Add small noise for stability\n","                k = k + torch.randn_like(k) * 0.01\n","            else:\n","                # If no features in cluster, use random initialization\n","                k = torch.randn(x_np.shape[1], latent_dim)\n","\n","            # Normalize columns\n","            k = k / (torch.norm(k, dim=0, keepdim=True) + 1e-6)\n","            k_matrices.append(k)\n","\n","        # Stack and move to device\n","        result = torch.stack(k_matrices).to(device)\n","        return result\n","    except Exception as e:\n","        print(f\"Clustered initialization error: {e}\")\n","        return create_random_k_matrix(x_data, num_factors, latent_dim, device)\n","\n","\n","def safe_mi_ksg_estimator(x, y, k=3):\n","    \"\"\"Robust KSG mutual information estimator.\"\"\"\n","    try:\n","        # Ensure inputs are NumPy arrays on CPU\n","        if isinstance(x, torch.Tensor):\n","            x = x.detach().cpu().numpy()\n","        if isinstance(y, torch.Tensor):\n","            y = y.detach().cpu().numpy()\n","\n","        x, y = x.flatten(), y.flatten()\n","        if len(x) < k + 1 or x.shape != y.shape:\n","            print(\"MI KSG: Invalid input shapes\")\n","            return 0.5\n","\n","        # Add small noise for numerical stability\n","        x = x + np.random.normal(0, 1e-10, x.shape)\n","        y = y + np.random.normal(0, 1e-10, y.shape)\n","\n","        n_samples = x.shape[0]\n","        xy = np.column_stack([x, y])\n","\n","        # Find nearest neighbors in joint space\n","        nn_joint = NearestNeighbors(metric='chebyshev').fit(xy)\n","        dist_joint = nn_joint.kneighbors(xy, k + 1)[0][:, k]\n","\n","        # Find points within epsilon radius in marginal spaces\n","        nn_x = NearestNeighbors(metric='chebyshev').fit(x.reshape(-1, 1))\n","        nn_y = NearestNeighbors(metric='chebyshev').fit(y.reshape(-1, 1))\n","\n","        nx = np.array([len(nn_x.radius_neighbors(x[i].reshape(1, -1), radius=dist_joint[i])[0]) for i in range(n_samples)])\n","        ny = np.array([len(nn_y.radius_neighbors(y[i].reshape(1, -1), radius=dist_joint[i])[0]) for i in range(n_samples)])\n","\n","        # Ensure counts are at least 1\n","        nx = np.maximum(nx, 1)\n","        ny = np.maximum(ny, 1)\n","\n","        # Calculate MI\n","        mi = np.mean(np.log(n_samples) + np.log(k) - np.log(nx) - np.log(ny))\n","\n","        # Normalize and clamp\n","        return max(0.0, min(1.0, mi / np.log(n_samples)))\n","    except Exception as e:\n","        print(f\"MI KSG error: {e}\")\n","        return 0.5\n","\n","def robust_total_correlation(z, num_factors, latent_dim, max_samples=5000):\n","    \"\"\"Calculate total correlation between latent factors.\"\"\"\n","    try:\n","        # Get the device of the input tensor\n","        device = z.device\n","\n","        # Check for NaNs or Infs\n","        if torch.isnan(z).any() or torch.isinf(z).any():\n","            print(\"TC Debug: Input contains NaN or Inf values!\")\n","            z = torch.nan_to_num(z, nan=0.5, posinf=1.0, neginf=0.0)\n","\n","        # Reshape correctly\n","        z_reshaped = z.view(-1, num_factors, latent_dim)\n","        n_samples = z_reshaped.shape[0]\n","\n","        # Skip computation for num_factors=1 (TC is always 0 for single factor)\n","        if num_factors <= 1:\n","            print(\"TC Debug: Single factor, TC is 0\")\n","            return torch.tensor(0.0, device=device)\n","\n","        if n_samples < num_factors * 10:\n","            print(f\"Total Correlation: Insufficient samples ({n_samples} < {num_factors * 10})\")\n","            return torch.tensor(0.5, device=device)\n","\n","        if n_samples > max_samples:\n","            indices = torch.randperm(n_samples, device=device)[:max_samples]\n","            z_reshaped = z_reshaped[indices]\n","            n_samples = max_samples\n","\n","        # Min-max normalization (keeping on original device)\n","        z_min, _ = z_reshaped.min(dim=0, keepdim=True)\n","        z_max, _ = z_reshaped.max(dim=0, keepdim=True)\n","        z_range = z_max - z_min + 1e-6\n","        z_reshaped = (z_reshaped - z_min) / z_range\n","\n","        # Add small noise to prevent exact zeros\n","        z_reshaped = z_reshaped + torch.randn_like(z_reshaped) * 1e-5\n","\n","        # Move to CPU for histogram computation\n","        z_cpu = z_reshaped.detach().cpu()\n","\n","        # Pairwise TC computation\n","        tc_scores = []\n","        # Use adaptive bin count based on sample size\n","        bin_count = min(30, max(10, int(np.sqrt(n_samples / 5))))\n","        #print(f\"TC Debug: Using {bin_count} bins for histograms\")\n","\n","        for i in range(num_factors):\n","            for j in range(i + 1, num_factors):\n","                try:\n","                    z_i = z_cpu[:, i, :].flatten()\n","                    z_j = z_cpu[:, j, :].flatten()\n","\n","                    # Calculate histograms on CPU\n","                    hist_i, bin_edges_i = np.histogram(z_i.numpy(), bins=bin_count, range=(0.0, 1.0), density=True)\n","                    hist_j, bin_edges_j = np.histogram(z_j.numpy(), bins=bin_count, range=(0.0, 1.0), density=True)\n","\n","                    # Remove zeros for log stability\n","                    hist_i = hist_i + 1e-10\n","                    hist_j = hist_j + 1e-10\n","\n","                    # Normalize\n","                    hist_i = hist_i / np.sum(hist_i)\n","                    hist_j = hist_j / np.sum(hist_j)\n","\n","                    # Calculate entropies\n","                    entropy_i = -np.sum(hist_i * np.log2(hist_i))\n","                    entropy_j = -np.sum(hist_j * np.log2(hist_j))\n","\n","                    # Joint histogram - simple 2D binning\n","                    joint_hist, _, _ = np.histogram2d(\n","                        z_i.numpy(), z_j.numpy(),\n","                        bins=bin_count,\n","                        range=[[0, 1], [0, 1]]\n","                    )\n","\n","                    # Normalize and handle zeros\n","                    joint_hist = joint_hist / np.sum(joint_hist) + 1e-10\n","\n","                    # Joint entropy\n","                    joint_entropy = -np.sum(joint_hist * np.log2(joint_hist))\n","\n","                    # MI calculation\n","                    mi = entropy_i + entropy_j - joint_entropy\n","\n","                    # Normalize to [0, 1]\n","                    max_entropy = np.log2(bin_count)\n","                    mi_normalized = mi / max_entropy\n","\n","                    tc_pair = max(0.0, min(0.95, mi_normalized))\n","                    tc_scores.append(tc_pair)\n","\n","                except Exception as e:\n","                    print(f\"TC Debug: Error in pair ({i},{j}): {e}\")\n","                    continue\n","\n","        if tc_scores:\n","            tc = np.mean(tc_scores)\n","            return torch.tensor(tc, device=device)  # Return on the original device\n","\n","        # Gaussian approximation fallback\n","        #print(\"TC Debug: Using Gaussian approximation fallback\")\n","\n","        # Compute on GPU if possible\n","        try:\n","            z_flat = z_reshaped.reshape(n_samples, -1)\n","\n","            # Add regularization for numerical stability\n","            eps = 1e-3 * torch.eye(z_flat.shape[1], device=device)\n","\n","            # Compute covariance with explicit formula\n","            z_centered = z_flat - z_flat.mean(dim=0, keepdim=True)\n","            cov_matrix = (z_centered.T @ z_centered) / (n_samples - 1) + eps\n","\n","            # Compute log determinant\n","            log_det_cov = torch.logdet(cov_matrix)\n","\n","            # Compute marginal variances\n","            marginal_vars = torch.var(z_reshaped, dim=0, unbiased=True).flatten()\n","            marginal_vars = torch.clamp(marginal_vars, min=1e-5)\n","            log_det_marginals = torch.sum(torch.log(marginal_vars))\n","\n","            # Calculate TC\n","            tc = 0.5 * (log_det_marginals - log_det_cov)\n","\n","            # Scale to [0,1]\n","            tc_scaled = 0.95 * torch.tanh(tc / np.log(n_samples))\n","            tc_value = max(0.0, min(0.95, tc_scaled.item()))\n","\n","            return torch.tensor(tc_value, device=device)\n","\n","        except Exception as e:\n","            #print(f\"TC Debug Gaussian fallback error: {e}\")\n","            return torch.tensor(0.5, device=device)\n","\n","    except Exception as e:\n","        print(f\"TC error: {e}\")\n","        return torch.tensor(0.5, device=device)\n","\n","\n","def robust_modularity_score(z, num_factors, latent_dim):\n","    \"\"\"Modularity score for latent factors.\"\"\"\n","    try:\n","        device = z.device\n","        z_reshaped = z.view(-1, num_factors, latent_dim)\n","\n","        # Special case for single factor\n","        if num_factors <= 1:\n","            return torch.tensor(1.0, device=device)\n","\n","        # Check for NaNs or Infs\n","        if torch.isnan(z_reshaped).any() or torch.isinf(z_reshaped).any():\n","            print(\"Modularity Debug: Input contains NaN or Inf values!\")\n","            z_reshaped = torch.nan_to_num(z_reshaped, nan=0.5, posinf=1.0, neginf=0.0)\n","\n","        modularity = 0.0\n","        count = 0\n","\n","        for i in range(num_factors):\n","            for j in range(i + 1, num_factors):\n","                z_i = z_reshaped[:, i, :].flatten()\n","                z_j = z_reshaped[:, j, :].flatten()\n","\n","                # Robust normalization\n","                z_i_mean, z_i_std = z_i.mean(), z_i.std() + 1e-8\n","                z_j_mean, z_j_std = z_j.mean(), z_j.std() + 1e-8\n","\n","                z_i = (z_i - z_i_mean) / z_i_std\n","                z_j = (z_j - z_j_mean) / z_j_std\n","\n","                # Clip to prevent extreme values\n","                z_i = torch.clamp(z_i, -10.0, 10.0)\n","                z_j = torch.clamp(z_j, -10.0, 10.0)\n","\n","                # Compute correlation\n","                corr = torch.abs(torch.mean(z_i * z_j))\n","\n","                if not torch.isnan(corr) and not torch.isinf(corr):\n","                    corr_val = corr.item()\n","                    # Correlation indicates dependence, so we take (1 - correlation) as modularity\n","                    modularity += 1.0 - min(1.0, max(0.0, corr_val))\n","                    count += 1\n","\n","        if count == 0:\n","            print(\"Modularity Debug: No valid correlations computed\")\n","            return torch.tensor(0.5, device=device)\n","\n","        result = modularity / count\n","\n","        # Final sanity check\n","        if result < 0 or result > 1 or np.isnan(result) or np.isinf(result):\n","            print(f\"Modularity Debug: Invalid final result: {result}\")\n","            return torch.tensor(0.5, device=device)\n","\n","        return torch.tensor(result, device=device)\n","\n","    except Exception as e:\n","        print(f\"Modularity error: {e}\")\n","        return torch.tensor(0.5, device=device)\n","\n","def robust_factor_vae_score(z, num_factors, latent_dim, n_samples=2000):\n","    \"\"\"Improved Factor VAE score using ElasticNet.\"\"\"\n","    try:\n","        # Ensure z is on CPU before NumPy conversion\n","        if isinstance(z, torch.Tensor):\n","            if z.device.type != 'cpu':\n","                z = z.detach().cpu()\n","\n","        # Special case for single factor\n","        if num_factors <= 1:\n","            return 0.5  # Default value for single factor\n","\n","        z_reshaped = z.view(-1, num_factors, latent_dim).detach().numpy()\n","\n","        if z_reshaped.shape[0] < num_factors or z_reshaped.shape[2] != latent_dim:\n","            print(\"FactorVAE: Invalid shape\")\n","            return 0.5\n","\n","        if z_reshaped.shape[0] > n_samples:\n","            indices = np.random.choice(z_reshaped.shape[0], n_samples, replace=False)\n","            z_reshaped = z_reshaped[indices]\n","\n","        # Standardize the data\n","        scaler = StandardScaler()\n","        z_reshaped = scaler.fit_transform(z_reshaped.reshape(z_reshaped.shape[0], -1)).reshape(z_reshaped.shape)\n","\n","        scores = []\n","        for j in range(num_factors):\n","            for k in range(latent_dim):\n","                target = z_reshaped[:, j, k]\n","                # Get all data from other factors\n","                other = z_reshaped[:, [i for i in range(num_factors) if i != j], :].reshape(z_reshaped.shape[0], -1)\n","\n","                if other.size == 0:\n","                    continue\n","\n","                # Split data for training and testing\n","                X_train, X_test, y_train, y_test = train_test_split(other, target, test_size=0.2, random_state=42)\n","\n","                # Train ElasticNet model\n","                model = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=1000)\n","                model.fit(X_train, y_train)\n","\n","                # Score is predictability (R)\n","                score = model.score(X_test, y_test)\n","\n","                # Higher independence (lower predictability) is better\n","                scores.append(max(0.0, min(1.0, 1.0 - score)))\n","\n","        return np.mean(scores) if scores else 0.5\n","    except Exception as e:\n","        print(f\"FactorVAE error: {e}\")\n","        return 0.5\n","\n","def robust_sap_score(z, x_data, num_factors, latent_dim):\n","    \"\"\"Improved SAP score using mutual information.\"\"\"\n","    try:\n","        # Ensure inputs are on CPU\n","        if isinstance(z, torch.Tensor):\n","            if z.device.type != 'cpu':\n","                z = z.detach().cpu()\n","        if isinstance(x_data, torch.Tensor):\n","            if x_data.device.type != 'cpu':\n","                x_data = x_data.detach().cpu()\n","\n","        # Special case for single factor\n","        if num_factors <= 1:\n","            return 0.5  # Default value for single factor\n","\n","        z_reshaped = z.view(-1, num_factors, latent_dim).numpy()\n","        x_np = x_data.numpy().reshape(x_data.shape[0], -1)\n","\n","        # Use a subset of features as proxies for true factors\n","        n_proxy = min(50, x_np.shape[1])\n","        proxy_indices = np.random.choice(x_np.shape[1], n_proxy, replace=False)\n","\n","        sap_scores = []\n","        for j in range(num_factors):\n","            for k in range(latent_dim):\n","                latent = z_reshaped[:, j, k]\n","\n","                # Calculate mutual information with each proxy\n","                mi_scores = []\n","                for p in proxy_indices:\n","                    if x_np[:, p].var() > 1e-6:  # Skip if variance is too low\n","                        mi = mutual_info_regression(latent.reshape(-1, 1), x_np[:, p])[0]\n","                        mi_scores.append(mi)\n","\n","                if len(mi_scores) > 1:\n","                    # Sort MI scores\n","                    sorted_mi = sorted(mi_scores, reverse=True)\n","                    # Gap between highest and second highest MI score indicates disentanglement\n","                    gap = (sorted_mi[0] - sorted_mi[1]) / (sorted_mi[0] + 1e-8)\n","                    sap_scores.append(max(0.0, min(1.0, gap)))\n","\n","        return np.mean(sap_scores) if sap_scores else 0.5\n","    except Exception as e:\n","        print(f\"SAP score error: {e}\")\n","        return 0.5\n","\n","\n","# ===== MAIN EXPERIMENT FUNCTIONS =====\n","\n","def run_comparison_experiment(dataset_names=None, output_dir='results'):\n","    \"\"\"\n","    Run the Universal K Matrix comparison experiment.\n","\n","    Args:\n","        dataset_names: List of datasets to test\n","        output_dir: Directory to save results\n","\n","    Returns:\n","        Dictionary of results\n","    \"\"\"\n","    print(\"Starting Universal K Matrix Comparison Experiment...\")\n","\n","    # Create output directory\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Set random seeds for reproducibility\n","    np.random.seed(42)\n","    torch.manual_seed(42)\n","\n","    # Set up device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"Using device: {device}\")\n","\n","    # Get available datasets\n","    available_datasets = get_available_datasets()\n","    if not dataset_names:\n","        dataset_names = [name for name, info in available_datasets.items() if info['available']]\n","\n","    # Define methods to test\n","    k_methods = [\n","        ('Clustered', create_clustered_k_matrix),\n","        ('PCA', create_pca_k_matrix),\n","        ('FactorAnalysis', create_factor_analysis_k_matrix)\n","    ]\n","\n","    # Define baseline methods\n","    baseline_methods = [\n","        'VIB',\n","        'BetaVAE',\n","        'SparseAutoencoder',\n","        'DropoutRegularizedModel'\n","    ]\n","\n","    # Define hyperparameters\n","    hyperparams = {\n","        'VIB': {'beta': [0.1, 1.0, 10.0]},\n","        'BetaVAE': {'beta': [0.1, 1.0, 10.0]},\n","        'SparseAutoencoder': {'sparsity_weight': [0.01, 0.1, 1.0]},\n","        'DropoutRegularizedModel': {'dropout_rate': [0.2, 0.5], 'weight_decay': [1e-4, 1e-5]},\n","        'KnowledgeDistillation': {'temperature': [2, 4], 'alpha': [0.3, 0.5, 0.7]}\n","    }\n","\n","    # Factors and dimensions to try\n","    factors_to_try = [3, 5]\n","    dims_to_try = [8, 16]\n","\n","    # Store all results\n","    results = {}\n","\n","    # Process each dataset\n","    for dataset_name in dataset_names:\n","        print(f\"\\nProcessing dataset: {dataset_name}\")\n","\n","        # Load or create dataset\n","        x_data, y_data, is_classification = load_or_create_dataset(dataset_name, available_datasets)\n","        print(f\"Dataset shape: {x_data.shape}, Classification: {is_classification}\")\n","\n","        # Create data loaders\n","        # Split into train/val/test\n","        train_size = int(0.7 * len(x_data))\n","        val_size = int(0.15 * len(x_data))\n","        test_size = len(x_data) - train_size - val_size\n","\n","        indices = torch.randperm(len(x_data))\n","        train_indices = indices[:train_size]\n","        val_indices = indices[train_size:train_size+val_size]\n","        test_indices = indices[train_size+val_size:]\n","\n","        # Create datasets\n","        train_x, train_y = x_data[train_indices], y_data[train_indices]\n","        val_x, val_y = x_data[val_indices], y_data[val_indices]\n","        test_x, test_y = x_data[test_indices], y_data[test_indices]\n","\n","        train_dataset = TensorDataset(train_x, train_y)\n","        val_dataset = TensorDataset(val_x, val_y)\n","        test_dataset = TensorDataset(test_x, test_y)\n","\n","        batch_size = 128\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","        # Initialize results for this dataset\n","        dataset_results = {\n","            'k_methods': {},\n","            'baseline_methods': {}\n","        }\n","\n","        # 1. Universal K Matrix Methods\n","        for method_name, method_func in k_methods:\n","            print(f\"\\nEvaluating Universal K method: {method_name}\")\n","            method_results = []\n","\n","            for num_factors in factors_to_try:\n","                for latent_dim in dims_to_try:\n","                    config_info = f\"[{method_name}, Factors={num_factors}, Dims={latent_dim}]\"\n","                    print(f\"Processing {config_info}\")\n","\n","                    try:\n","                        # Initialize K matrix\n","                        start_time = time.time()\n","                        k_matrix = method_func(train_x.to(device), num_factors, latent_dim, device)\n","                        init_time = time.time() - start_time\n","\n","                        # Refine K matrix\n","                        start_time = time.time()\n","                        k_refined = refine_k_matrix(train_x.to(device), k_matrix, num_factors, latent_dim, device, epochs=100)\n","                        refine_time = time.time() - start_time\n","\n","                        # Evaluate K matrix\n","                        metrics = evaluate_k_matrix(val_x.to(device), k_refined, num_factors, latent_dim, device)\n","\n","                        # Calculate combined score\n","                        combined_score = (\n","                            (1.0 - metrics['mi_ksg']) * 0.2 +\n","                            metrics['modularity'] * 0.2 +\n","                            (1.0 - metrics['total_correlation']) * 0.2 +\n","                            metrics['factor_vae_score'] * 0.2 +\n","                            metrics['sap_score'] * 0.2\n","                        )\n","\n","                        # Encode data with K matrix\n","                        z_train = encode_data(train_x.to(device), k_refined)\n","                        z_val = encode_data(val_x.to(device), k_refined)\n","                        z_test = encode_data(test_x.to(device), k_refined)\n","\n","                        # Create datasets with latent codes\n","                        latent_train_dataset = TensorDataset(z_train.reshape(z_train.shape[0], -1), train_y.to(device))\n","                        latent_val_dataset = TensorDataset(z_val.reshape(z_val.shape[0], -1), val_y.to(device))\n","                        latent_test_dataset = TensorDataset(z_test.reshape(z_test.shape[0], -1), test_y.to(device))\n","\n","                        latent_train_loader = DataLoader(latent_train_dataset, batch_size=batch_size, shuffle=True)\n","                        latent_val_loader = DataLoader(latent_val_dataset, batch_size=batch_size)\n","                        latent_test_loader = DataLoader(latent_test_dataset, batch_size=batch_size)\n","\n","                        # Train task model on latent codes\n","                        input_dim = z_train.reshape(z_train.shape[0], -1).shape[1]\n","\n","                        if is_classification:\n","                            # For multi-class classification\n","                            num_classes = len(torch.unique(train_y))\n","                            model = nn.Sequential(\n","                                nn.Linear(input_dim, 128),\n","                                nn.ReLU(),\n","                                nn.Linear(128, 64),\n","                                nn.ReLU(),\n","                                nn.Linear(64, num_classes)\n","                            ).to(device)\n","                        else:\n","                            # For regression\n","                            model = nn.Sequential(\n","                                nn.Linear(input_dim, 128),\n","                                nn.ReLU(),\n","                                nn.Linear(128, 64),\n","                                nn.ReLU(),\n","                                nn.Linear(64, 1)\n","                            ).to(device)\n","\n","                        # Train model\n","                        model = train_model(model, latent_train_loader, latent_val_loader, device, is_classification)\n","\n","                        # Evaluate model\n","                        task_metrics = evaluate_model_metrics(model, latent_test_loader, device, is_classification)\n","\n","                        # Store the performance metric\n","                        if is_classification:\n","                            performance = task_metrics['accuracy']\n","                        else:\n","                            performance = task_metrics['mse']\n","\n","                        # Add results\n","                        result = {\n","                            'method': method_name,\n","                            'num_factors': num_factors,\n","                            'latent_dim': latent_dim,\n","                            'metrics': metrics,\n","                            'combined_score': combined_score,\n","                            'init_time': init_time,\n","                            'refine_time': refine_time,\n","                            'teacher_performance': performance,\n","                            'task_metrics': task_metrics,\n","                            'k_matrix': k_refined.detach().cpu()\n","                        }\n","\n","                        method_results.append(result)\n","\n","                        # Log results\n","                        print(f\"{config_info} - Combined score: {combined_score:.4f}\")\n","                        if is_classification:\n","                            print(f\"{config_info} - Accuracy: {performance:.4f}\")\n","                        else:\n","                            print(f\"{config_info} - MSE: {performance:.4f}\")\n","\n","                    except Exception as e:\n","                        print(f\"Error processing {config_info}: {e}\")\n","\n","            # Store results for this method\n","            dataset_results['k_methods'][method_name] = method_results\n","\n","        # 2. Baseline Methods\n","        for method_name in baseline_methods:\n","            print(f\"\\nEvaluating baseline method: {method_name}\")\n","            method_results = []\n","\n","            # Get hyperparameter combinations\n","            method_hyperparams = hyperparams.get(method_name, {})\n","            hyperparam_keys = list(method_hyperparams.keys())\n","            hyperparam_values = list(method_hyperparams.values())\n","\n","            # Generate all combinations\n","            hyperparam_combinations = []\n","            if hyperparam_keys:\n","                import itertools\n","                hyperparam_combinations = list(itertools.product(*hyperparam_values))\n","            else:\n","                hyperparam_combinations = [()]\n","\n","            for params in hyperparam_combinations:\n","                # Create parameter dictionary\n","                param_dict = {key: value for key, value in zip(hyperparam_keys, params)}\n","\n","                # For models with latent space, test with different latent dimensions\n","                if method_name in ['VIB', 'BetaVAE', 'SparseAutoencoder']:\n","                    for num_factors in factors_to_try:\n","                        for latent_dim in dims_to_try:\n","                            total_latent_dim = num_factors * latent_dim\n","\n","                            config_info = f\"[{method_name}, Factors={num_factors}, Dims={latent_dim}, Params={param_dict}]\"\n","                            print(f\"Processing {config_info}\")\n","\n","                            try:\n","                                # Initialize model\n","                                input_dim = x_data.shape[1]\n","                                hidden_dim = 256\n","\n","                                if method_name == 'VIB':\n","                                    if is_classification:\n","                                        num_classes = len(torch.unique(train_y))\n","                                        model = VIB(input_dim, hidden_dim, total_latent_dim, beta=param_dict.get('beta', 1.0))\n","                                        # Adjust predictor for classification\n","                                        model.predictor = nn.Sequential(\n","                                            nn.Linear(total_latent_dim, hidden_dim // 2),\n","                                            nn.LeakyReLU(0.2),\n","                                            nn.Linear(hidden_dim // 2, num_classes)\n","                                        )\n","                                    else:\n","                                        model = VIB(input_dim, hidden_dim, total_latent_dim, beta=param_dict.get('beta', 1.0))\n","\n","                                elif method_name == 'BetaVAE':\n","                                    if is_classification:\n","                                        num_classes = len(torch.unique(train_y))\n","                                        model = BetaVAE(input_dim, hidden_dim, total_latent_dim, beta=param_dict.get('beta', 1.0))\n","                                        # Adjust predictor for classification\n","                                        model.predictor = nn.Sequential(\n","                                            nn.Linear(total_latent_dim, hidden_dim // 2),\n","                                            nn.LeakyReLU(0.2),\n","                                            nn.Linear(hidden_dim // 2, num_classes)\n","                                        )\n","                                    else:\n","                                        model = BetaVAE(input_dim, hidden_dim, total_latent_dim, beta=param_dict.get('beta', 1.0))\n","\n","                                elif method_name == 'SparseAutoencoder':\n","                                    if is_classification:\n","                                        num_classes = len(torch.unique(train_y))\n","                                        model = SparseAutoencoder(input_dim, hidden_dim, total_latent_dim, sparsity_weight=param_dict.get('sparsity_weight', 0.01))\n","                                        # Adjust predictor for classification\n","                                        model.predictor = nn.Sequential(\n","                                            nn.Linear(total_latent_dim, hidden_dim // 2),\n","                                            nn.LeakyReLU(0.2),\n","                                            nn.Linear(hidden_dim // 2, num_classes)\n","                                        )\n","                                    else:\n","                                        model = SparseAutoencoder(input_dim, hidden_dim, total_latent_dim, sparsity_weight=param_dict.get('sparsity_weight', 0.01))\n","\n","                                # Move model to device\n","                                model = model.to(device)\n","\n","                                # Train model\n","                                model = train_model(model, train_loader, val_loader, device, is_classification)\n","\n","                                # Evaluate model\n","                                metrics = evaluate_baseline_method(method_name, model, test_loader, device, is_classification, None, num_factors, latent_dim)\n","\n","                                # Add performance metric\n","                                if is_classification:\n","                                    metrics['performance'] = metrics['task_metrics']['accuracy']\n","                                else:\n","                                    metrics['performance'] = metrics['task_metrics']['mse']\n","\n","                                # Add results\n","                                result = {\n","                                    'method': method_name,\n","                                    'params': param_dict,\n","                                    'num_factors': num_factors,\n","                                    'latent_dim': latent_dim,\n","                                    'metrics': metrics,\n","                                    'performance': metrics['performance']\n","                                }\n","\n","                                method_results.append(result)\n","\n","                                # Log results\n","                                if is_classification:\n","                                    print(f\"{config_info} - Accuracy: {metrics['performance']:.4f}\")\n","                                else:\n","                                    print(f\"{config_info} - MSE: {metrics['performance']:.4f}\")\n","\n","                            except Exception as e:\n","                                print(f\"Error processing {config_info}: {e}\")\n","                else:\n","                    # For models without latent space\n","                    config_info = f\"[{method_name}, Params={param_dict}]\"\n","                    print(f\"Processing {config_info}\")\n","\n","                    try:\n","                        # Initialize model\n","                        input_dim = x_data.shape[1]\n","                        hidden_dim = 256\n","\n","                        if method_name == 'DropoutRegularizedModel':\n","                            if is_classification:\n","                                num_classes = len(torch.unique(train_y))\n","                                model = DropoutRegularizedModel(input_dim, hidden_dim, num_classes, dropout_rate=param_dict.get('dropout_rate', 0.5))\n","                            else:\n","                                model = DropoutRegularizedModel(input_dim, hidden_dim, 1, dropout_rate=param_dict.get('dropout_rate', 0.5))\n","\n","                        # Move model to device\n","                        model = model.to(device)\n","\n","                        # Create optimizer with weight decay\n","                        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=param_dict.get('weight_decay', 0.0))\n","\n","                        # Train model\n","                        criterion = nn.CrossEntropyLoss() if is_classification else nn.MSELoss()\n","\n","                        # Train for specified epochs with early stopping\n","                        best_val_loss = float('inf')\n","                        early_stop_counter = 0\n","\n","                        for epoch in range(50):  # 50 epochs max\n","                            # Training\n","                            model.train()\n","                            for batch_x, batch_y in train_loader:\n","                                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","\n","                                optimizer.zero_grad()\n","                                outputs = model(batch_x)\n","                                loss = criterion(outputs, batch_y)\n","                                loss.backward()\n","                                optimizer.step()\n","\n","                            # Validation\n","                            model.eval()\n","                            val_loss = 0.0\n","                            with torch.no_grad():\n","                                for batch_x, batch_y in val_loader:\n","                                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","\n","                                    outputs = model(batch_x)\n","                                    loss = criterion(outputs, batch_y)\n","                                    val_loss += loss.item()\n","\n","                            val_loss /= len(val_loader)\n","\n","                            # Early stopping\n","                            if val_loss < best_val_loss:\n","                                best_val_loss = val_loss\n","                                early_stop_counter = 0\n","                            else:\n","                                early_stop_counter += 1\n","                                if early_stop_counter >= 5:  # Stop after 5 epochs without improvement\n","                                    break\n","\n","                        # Evaluate model\n","                        task_metrics = evaluate_model_metrics(model, test_loader, device, is_classification)\n","\n","                        # Add results\n","                        result = {\n","                            'method': method_name,\n","                            'params': param_dict,\n","                            'metrics': {'task_metrics': task_metrics},\n","                            'performance': task_metrics['accuracy'] if is_classification else task_metrics['mse']\n","                        }\n","\n","                        method_results.append(result)\n","\n","                        # Log results\n","                        if is_classification:\n","                            print(f\"{config_info} - Accuracy: {task_metrics['accuracy']:.4f}\")\n","                        else:\n","                            print(f\"{config_info} - MSE: {task_metrics['mse']:.4f}\")\n","\n","                    except Exception as e:\n","                        print(f\"Error processing {config_info}: {e}\")\n","\n","            # Store results for this method\n","            dataset_results['baseline_methods'][method_name] = method_results\n","\n","        # 3. Knowledge Distillation (if applicable)\n","        if dataset_results['k_methods']:\n","            print(\"\\nEvaluating Knowledge Distillation\")\n","\n","            # Find best K matrix method\n","            best_k_method = None\n","            best_k_score = -float('inf')\n","            best_k_config = None\n","\n","            for method_name, method_results in dataset_results['k_methods'].items():\n","                for result in method_results:\n","                    if result['combined_score'] > best_k_score:\n","                        best_k_score = result['combined_score']\n","                        best_k_method = method_name\n","                        best_k_config = result\n","\n","            if best_k_config:\n","                print(f\"Using best K matrix method for distillation: {best_k_method}\")\n","\n","                # Extract best K matrix\n","                k_matrix = best_k_config['k_matrix'].to(device)\n","                num_factors = best_k_config['num_factors']\n","                latent_dim = best_k_config['latent_dim']\n","\n","                # Encode data with K matrix\n","                z_train = encode_data(train_x.to(device), k_matrix)\n","                z_val = encode_data(val_x.to(device), k_matrix)\n","                z_test = encode_data(test_x.to(device), k_matrix)\n","\n","                # Create latent datasets\n","                latent_train_dataset = TensorDataset(z_train.reshape(z_train.shape[0], -1), train_y.to(device))\n","                latent_val_dataset = TensorDataset(z_val.reshape(z_val.shape[0], -1), val_y.to(device))\n","                latent_test_dataset = TensorDataset(z_test.reshape(z_test.shape[0], -1), test_y.to(device))\n","\n","                latent_train_loader = DataLoader(latent_train_dataset, batch_size=batch_size, shuffle=True)\n","                latent_val_loader = DataLoader(latent_val_dataset, batch_size=batch_size)\n","                latent_test_loader = DataLoader(latent_test_dataset, batch_size=batch_size)\n","\n","                # Create teacher model\n","                input_dim = z_train.reshape(z_train.shape[0], -1).shape[1]\n","\n","                if is_classification:\n","                    num_classes = len(torch.unique(train_y))\n","                    teacher_model = nn.Sequential(\n","                        nn.Linear(input_dim, 128),\n","                        nn.ReLU(),\n","                        nn.Linear(128, 64),\n","                        nn.ReLU(),\n","                        nn.Linear(64, num_classes)\n","                    ).to(device)\n","                else:\n","                    teacher_model = nn.Sequential(\n","                        nn.Linear(input_dim, 128),\n","                        nn.ReLU(),\n","                        nn.Linear(128, 64),\n","                        nn.ReLU(),\n","                        nn.Linear(64, 1)\n","                    ).to(device)\n","\n","                # Train teacher model\n","                teacher_model = train_model(teacher_model, latent_train_loader, latent_val_loader, device, is_classification)\n","\n","                # Evaluate teacher model\n","                teacher_metrics = evaluate_model_metrics(teacher_model, latent_test_loader, device, is_classification)\n","\n","                # Create student model (smaller than teacher)\n","                if is_classification:\n","                    student_model = nn.Sequential(\n","                        nn.Linear(input_dim, 64),\n","                        nn.ReLU(),\n","                        nn.Linear(64, num_classes)\n","                    ).to(device)\n","                else:\n","                    student_model = nn.Sequential(\n","                        nn.Linear(input_dim, 64),\n","                        nn.ReLU(),\n","                        nn.Linear(64, 1)\n","                    ).to(device)\n","\n","                # Run knowledge distillation experiments\n","                kd_results = []\n","\n","                for temp in hyperparams['KnowledgeDistillation']['temperature']:\n","                    for alpha in hyperparams['KnowledgeDistillation']['alpha']:\n","                        config_info = f\"[KD, Temp={temp}, Alpha={alpha}]\"\n","                        print(f\"Processing {config_info}\")\n","\n","                        try:\n","                            # Optimizer for student\n","                            optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n","\n","                            # Train with knowledge distillation\n","                            best_val_loss = float('inf')\n","                            early_stop_counter = 0\n","\n","                            for epoch in range(50):\n","                                # Training\n","                                student_model.train()\n","                                teacher_model.eval()\n","\n","                                for batch_z, batch_y in latent_train_loader:\n","                                    optimizer.zero_grad()\n","\n","                                    # Forward passes\n","                                    with torch.no_grad():\n","                                        teacher_outputs = teacher_model(batch_z)\n","\n","                                    student_outputs = student_model(batch_z)\n","\n","                                    # Knowledge distillation loss\n","                                    loss = knowledge_distillation_loss(\n","                                        student_outputs, teacher_outputs, batch_y,\n","                                        temperature=temp, alpha=alpha\n","                                    )\n","\n","                                    loss.backward()\n","                                    optimizer.step()\n","\n","                                # Validation\n","                                student_model.eval()\n","                                val_loss = 0.0\n","\n","                                with torch.no_grad():\n","                                    for batch_z, batch_y in latent_val_loader:\n","                                        student_outputs = student_model(batch_z)\n","\n","                                        if is_classification:\n","                                            loss = F.cross_entropy(student_outputs, batch_y)\n","                                        else:\n","                                            loss = F.mse_loss(student_outputs, batch_y)\n","\n","                                        val_loss += loss.item()\n","\n","                                val_loss /= len(latent_val_loader)\n","\n","                                # Early stopping\n","                                if val_loss < best_val_loss:\n","                                    best_val_loss = val_loss\n","                                    early_stop_counter = 0\n","                                else:\n","                                    early_stop_counter += 1\n","                                    if early_stop_counter >= 5:  # Stop after 5 epochs without improvement\n","                                        break\n","\n","                            # Evaluate student model\n","                            student_metrics = evaluate_model_metrics(student_model, latent_test_loader, device, is_classification)\n","\n","                            # Add results\n","                            result = {\n","                                'method': 'KnowledgeDistillation',\n","                                'temperature': temp,\n","                                'alpha': alpha,\n","                                'metrics': student_metrics,\n","                                'performance': student_metrics['accuracy'] if is_classification else student_metrics['mse'],\n","                                'teacher_method': best_k_method,\n","                                'num_factors': num_factors,\n","                                'latent_dim': latent_dim\n","                            }\n","\n","                            kd_results.append(result)\n","\n","                            # Log results\n","                            if is_classification:\n","                                print(f\"{config_info} - Accuracy: {student_metrics['accuracy']:.4f}\")\n","                            else:\n","                                print(f\"{config_info} - MSE: {student_metrics['mse']:.4f}\")\n","\n","                        except Exception as e:\n","                            print(f\"Error processing {config_info}: {e}\")\n","\n","                dataset_results['KnowledgeDistillation'] = kd_results\n","\n","        # Store results for this dataset\n","        results[dataset_name] = dataset_results\n","\n","        # Save intermediate results to CSV\n","        save_metrics_to_csv({dataset_name: dataset_results}, output_dir)\n","\n","    # Save final results to CSV\n","    save_metrics_to_csv(results, output_dir)\n","\n","    return results\n","\n","def compare_universal_k_with_baselines(results):\n","    \"\"\"\n","    Compare performance of Universal K approach with baseline methods.\n","\n","    Args:\n","        results: Dictionary of results\n","\n","    Returns:\n","        DataFrame with comparisons\n","    \"\"\"\n","    comparison_rows = []\n","\n","    for dataset_name, dataset_results in results.items():\n","        # Determine if classification or regression task\n","        is_classification = False\n","        task_metric = 'mse'  # Default to regression metric\n","\n","        # Check in k_methods first\n","        if 'k_methods' in dataset_results and dataset_results['k_methods']:\n","            method_name = next(iter(dataset_results['k_methods']))\n","            method_results = dataset_results['k_methods'][method_name]\n","            if method_results and 'teacher_performance' in method_results[0]:\n","                # If performance is between 0 and 1, likely accuracy\n","                if 0 <= method_results[0]['teacher_performance'] <= 1:\n","                    is_classification = True\n","                    task_metric = 'accuracy'\n","\n","        # Get best Universal K result\n","        best_k_performance = float('-inf') if is_classification else float('inf')\n","        best_k_method = None\n","        best_k_config = None\n","\n","        if 'k_methods' in dataset_results:\n","            for method_name, method_results in dataset_results['k_methods'].items():\n","                for result in method_results:\n","                    perf = result.get('teacher_performance', None)\n","                    if perf is not None:\n","                        better = (is_classification and perf > best_k_performance) or (not is_classification and perf < best_k_performance)\n","                        if better:\n","                            best_k_performance = perf\n","                            best_k_method = method_name\n","                            best_k_config = result\n","\n","        # Get best baseline result\n","        best_baseline_performance = float('-inf') if is_classification else float('inf')\n","        best_baseline_method = None\n","        best_baseline_config = None\n","\n","        if 'baseline_methods' in dataset_results:\n","            for method_name, method_results in dataset_results['baseline_methods'].items():\n","                for result in method_results:\n","                    perf = result.get('performance', None)\n","                    if perf is not None:\n","                        better = (is_classification and perf > best_baseline_performance) or (not is_classification and perf < best_baseline_performance)\n","                        if better:\n","                            best_baseline_performance = perf\n","                            best_baseline_method = method_name\n","                            best_baseline_config = result\n","\n","        # Get best distillation result\n","        best_kd_performance = float('-inf') if is_classification else float('inf')\n","        best_kd_config = None\n","\n","        if 'KnowledgeDistillation' in dataset_results:\n","            for result in dataset_results['KnowledgeDistillation']:\n","                perf = result.get('performance', None)\n","                if perf is not None:\n","                    better = (is_classification and perf > best_kd_performance) or (not is_classification and perf < best_kd_performance)\n","                    if better:\n","                        best_kd_performance = perf\n","                        best_kd_config = result\n","\n","        # Add row to comparison\n","        row = {\n","            'dataset': dataset_name,\n","            'is_classification': is_classification,\n","            'metric': task_metric\n","        }\n","\n","        # Add Universal K details\n","        if best_k_method:\n","            row['best_k_method'] = best_k_method\n","            row['best_k_num_factors'] = best_k_config['num_factors']\n","            row['best_k_latent_dim'] = best_k_config['latent_dim']\n","            row['best_k_performance'] = best_k_performance\n","            row['best_k_combined_score'] = best_k_config['combined_score']\n","\n","        # Add baseline details\n","        if best_baseline_method:\n","            row['best_baseline_method'] = best_baseline_method\n","\n","            # Add hyperparameters if available\n","            if 'params' in best_baseline_config:\n","                for param_name, param_value in best_baseline_config['params'].items():\n","                    row[f'best_baseline_{param_name}'] = param_value\n","\n","            row['best_baseline_performance'] = best_baseline_performance\n","\n","        # Add distillation details\n","        if best_kd_config:\n","            row['best_kd_temperature'] = best_kd_config['temperature']\n","            row['best_kd_alpha'] = best_kd_config['alpha']\n","            row['best_kd_performance'] = best_kd_performance\n","\n","        # Calculate performance differences\n","        if best_k_method and best_baseline_method:\n","            if is_classification:\n","                row['k_vs_baseline_diff'] = best_k_performance - best_baseline_performance\n","                row['k_better_than_baseline'] = best_k_performance > best_baseline_performance\n","            else:\n","                row['k_vs_baseline_diff'] = best_baseline_performance - best_k_performance  # Lower is better for regression\n","                row['k_better_than_baseline'] = best_k_performance < best_baseline_performance\n","\n","        if best_k_method and best_kd_config:\n","            if is_classification:\n","                row['k_vs_kd_diff'] = best_k_performance - best_kd_performance\n","                row['k_better_than_kd'] = best_k_performance > best_kd_performance\n","            else:\n","                row['k_vs_kd_diff'] = best_kd_performance - best_k_performance  # Lower is better for regression\n","                row['k_better_than_kd'] = best_k_performance < best_kd_performance\n","\n","        comparison_rows.append(row)\n","\n","    # Create DataFrame\n","    comparison_df = pd.DataFrame(comparison_rows)\n","    return comparison_df\n","\n","def create_random_k_matrix(x_data, num_factors, latent_dim, device):\n","    \"\"\"Create random orthogonal K matrices.\"\"\"\n","    try:\n","        # Get input feature dimension\n","        n_features = x_data.shape[1]\n","\n","        # Initialize on the correct device\n","        k_matrices = []\n","\n","        for i in range(num_factors):\n","            # Create random matrix\n","            k = torch.randn(n_features, latent_dim, device=device)\n","\n","            # Make orthogonal to previous factors\n","            for prev_k in k_matrices:\n","                k = k - torch.mm(prev_k, torch.mm(prev_k.t(), k))\n","\n","            # QR decomposition for orthogonalization\n","            if torch.linalg.matrix_rank(k) > 0:  # Check if matrix is not all zeros\n","                q, r = torch.linalg.qr(k)\n","                k = q[:, :latent_dim]\n","            else:\n","                # If rank is 0, just use random normalized matrix\n","                k = torch.randn(n_features, latent_dim, device=device)\n","                k = k / (torch.norm(k, dim=0, keepdim=True) + 1e-8)\n","\n","            k_matrices.append(k)\n","\n","        return torch.stack(k_matrices)\n","    except Exception as e:\n","        print(f\"Random initialization error: {e}\")\n","        # Ultimate fallback\n","        return torch.randn(num_factors, x_data.shape[1], latent_dim, device=device)\n","\n","def sparsity_score(k_matrix):\n","    \"\"\"Improved sparsity score with numerical stability.\"\"\"\n","    try:\n","        # Get device from input tensor\n","        device = k_matrix.device\n","\n","        # Add small noise for numerical stability\n","        k_matrix = k_matrix + 1e-6 * torch.randn_like(k_matrix)\n","\n","        l1_norm = torch.sum(torch.abs(k_matrix))\n","        l2_norm = torch.sqrt(torch.sum(k_matrix ** 2) + 1e-6)\n","        n_elements = float(torch.numel(k_matrix))\n","\n","        # Create tensor on the same device\n","        n_elements_tensor = torch.tensor(n_elements, dtype=torch.float, device=device)\n","\n","        sparsity = 1.0 - (l1_norm / (l2_norm * torch.sqrt(n_elements_tensor) + 1e-6))\n","\n","        # Create min/max tensors on the same device\n","        min_val = torch.tensor(0.1, device=device)\n","        max_val = torch.tensor(0.9, device=device)\n","        sparsity_val = torch.clamp(sparsity, min_val, max_val)\n","\n","        if torch.isnan(sparsity_val) or torch.isinf(sparsity_val):\n","            print(f\"Sparsity is NaN or Inf\")\n","            return torch.tensor(0.5, device=device)\n","\n","        return sparsity_val\n","\n","    except Exception as e:\n","        print(f\"Sparsity error: {e}\")\n","        # Ensure return value is on the same device\n","        return torch.tensor(0.5, device=device if device is not None else 'cpu')\n","\n","\n","\n","# ===== MODEL IMPLEMENTATIONS =====\n","\n","class VIB(nn.Module):\n","    \"\"\"Variational Information Bottleneck Autoencoder.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, latent_dim, beta=1.0):\n","        super(VIB, self).__init__()\n","\n","        self.beta = beta\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2)\n","        )\n","\n","        # Latent parameters\n","        self.mu = nn.Linear(hidden_dim // 2, latent_dim)\n","        self.log_var = nn.Linear(hidden_dim // 2, latent_dim)\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, input_dim)\n","        )\n","\n","        # Task predictor\n","        self.predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, 1)  # For regression, will be adjusted for classification\n","        )\n","\n","    def encode(self, x):\n","        h = self.encoder(x)\n","        return self.mu(h), self.log_var(h)\n","\n","    def reparameterize(self, mu, log_var):\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def predict(self, z):\n","        return self.predictor(z)\n","\n","    def forward(self, x):\n","        mu, log_var = self.encode(x)\n","        z = self.reparameterize(mu, log_var)\n","        x_recon = self.decode(z)\n","        pred = self.predict(z)\n","        return x_recon, mu, log_var, z, pred\n","\n","    def loss_function(self, x, x_recon, mu, log_var, y, pred):\n","        # Reconstruction loss\n","        recon_loss = F.mse_loss(x_recon, x)\n","\n","        # KL divergence\n","        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","\n","        # Task loss (MSE for regression, will be adjusted for classification)\n","        task_loss = F.mse_loss(pred, y)\n","\n","        # Total loss\n","        total_loss = task_loss + self.beta * kl_loss + recon_loss\n","\n","        return total_loss, recon_loss, kl_loss, task_loss\n","\n","\n","class BetaVAE(nn.Module):\n","    \"\"\"Beta-VAE for disentangled representation learning.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, latent_dim, beta=1.0):\n","        super(BetaVAE, self).__init__()\n","\n","        self.beta = beta\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2)\n","        )\n","\n","        # Latent parameters\n","        self.mu = nn.Linear(hidden_dim // 2, latent_dim)\n","        self.log_var = nn.Linear(hidden_dim // 2, latent_dim)\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, input_dim)\n","        )\n","\n","        # Task predictor\n","        self.predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, 1)  # For regression, will be adjusted for classification\n","        )\n","\n","    def encode(self, x):\n","        h = self.encoder(x)\n","        return self.mu(h), self.log_var(h)\n","\n","    def reparameterize(self, mu, log_var):\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def predict(self, z):\n","        return self.predictor(z)\n","\n","    def forward(self, x):\n","        mu, log_var = self.encode(x)\n","        z = self.reparameterize(mu, log_var)\n","        x_recon = self.decode(z)\n","        pred = self.predict(z)\n","        return x_recon, mu, log_var, z, pred\n","\n","    def loss_function(self, x, x_recon, mu, log_var, y, pred):\n","        # Reconstruction loss\n","        recon_loss = F.mse_loss(x_recon, x)\n","\n","        # KL divergence with beta scaling\n","        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","\n","        # Task loss\n","        task_loss = F.mse_loss(pred, y)\n","\n","        # Total loss with beta weighting\n","        total_loss = task_loss + self.beta * kl_loss + recon_loss\n","\n","        return total_loss, recon_loss, kl_loss, task_loss\n","\n","\n","class DropoutRegularizedModel(nn.Module):\n","    \"\"\"Neural network with dropout and weight decay for regularization.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.5):\n","        super(DropoutRegularizedModel, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_dim // 2, output_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","class SparseAutoencoder(nn.Module):\n","    \"\"\"Autoencoder with L1 sparsity regularization.\"\"\"\n","    def __init__(self, input_dim, hidden_dim, latent_dim, sparsity_weight=0.01):\n","        super(SparseAutoencoder, self).__init__()\n","\n","        self.sparsity_weight = sparsity_weight\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, latent_dim)\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim, input_dim)\n","        )\n","\n","        # Task predictor\n","        self.predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(hidden_dim // 2, 1)  # For regression, will be adjusted for classification\n","        )\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        x_recon = self.decoder(z)\n","        pred = self.predictor(z)\n","        return x_recon, z, pred\n","\n","    def loss_function(self, x, x_recon, z, y, pred):\n","        # Reconstruction loss\n","        recon_loss = F.mse_loss(x_recon, x)\n","\n","        # L1 sparsity regularization\n","        sparsity_loss = torch.mean(torch.abs(z))\n","\n","        # Task loss\n","        task_loss = F.mse_loss(pred, y)\n","\n","        # Total loss\n","        total_loss = task_loss + recon_loss + self.sparsity_weight * sparsity_loss\n","\n","        return total_loss, recon_loss, sparsity_loss, task_loss\n","\n","\n","# ===== DISTILLATION METHODS =====\n","\n","def knowledge_distillation_loss(student_logits, teacher_logits, y_true, temperature=4.0, alpha=0.5):\n","    \"\"\"\n","    Compute the knowledge distillation loss.\n","\n","    Args:\n","        student_logits: Logits from the student model\n","        teacher_logits: Logits from the teacher model\n","        y_true: Ground truth labels\n","        temperature: Softmax temperature for distillation\n","        alpha: Weight for distillation loss vs. task loss\n","\n","    Returns:\n","        The combined loss\n","    \"\"\"\n","    # For classification tasks\n","    if len(y_true.shape) == 1:  # Labels are indices\n","        # Task loss\n","        task_loss = F.cross_entropy(student_logits, y_true)\n","\n","        # Distillation loss\n","        # Scale logits by temperature and compute soft targets\n","        soft_targets = F.softmax(teacher_logits / temperature, dim=1)\n","        log_probs = F.log_softmax(student_logits / temperature, dim=1)\n","        distillation_loss = -(soft_targets * log_probs).sum(dim=1).mean() * (temperature ** 2)\n","\n","        # Combined loss\n","        loss = alpha * distillation_loss + (1 - alpha) * task_loss\n","\n","    # For regression tasks\n","    else:\n","        # Task loss\n","        task_loss = F.mse_loss(student_logits, y_true)\n","\n","        # Distillation loss - MSE between student and teacher outputs\n","        distillation_loss = F.mse_loss(student_logits, teacher_logits)\n","\n","        # Combined loss\n","        loss = alpha * distillation_loss + (1 - alpha) * task_loss\n","\n","    return loss\n","\n","def attention_transfer_loss(student_features, teacher_features, y_true, model_output, beta=0.5):\n","    \"\"\"\n","    Compute the attention transfer loss.\n","\n","    Args:\n","        student_features: List of feature maps from student model\n","        teacher_features: List of feature maps from teacher model\n","        y_true: Ground truth labels\n","        model_output: Output from the student model\n","        beta: Weight for attention loss vs. task loss\n","\n","    Returns:\n","        The combined loss\n","    \"\"\"\n","    # Task loss (classification or regression)\n","    if len(y_true.shape) == 1:  # Classification with class indices\n","        task_loss = F.cross_entropy(model_output, y_true)\n","    else:  # Regression\n","        task_loss = F.mse_loss(model_output, y_true)\n","\n","    # Attention transfer loss\n","    attention_loss = 0.0\n","    for student_feat, teacher_feat in zip(student_features, teacher_features):\n","        # Compute normalized attention maps\n","        student_attention = F.normalize(student_feat.pow(2).mean(1).view(student_feat.size(0), -1), p=2, dim=1)\n","        teacher_attention = F.normalize(teacher_feat.pow(2).mean(1).view(teacher_feat.size(0), -1), p=2, dim=1)\n","\n","        # L2 distance between attention maps\n","        attention_loss += F.mse_loss(student_attention, teacher_attention)\n","\n","    # Combined loss\n","    loss = task_loss + beta * attention_loss\n","\n","    return loss\n","\n","\n","# ===== EVALUATION FUNCTIONS =====\n","\n","def evaluate_model_metrics(model, dataloader, device, is_classification=True):\n","    \"\"\"\n","    Evaluate a model and return comprehensive metrics.\n","\n","    Args:\n","        model: The trained model to evaluate\n","        dataloader: DataLoader for evaluation data\n","        device: Device to run evaluation on\n","        is_classification: Whether this is a classification task\n","\n","    Returns:\n","        Dictionary of metrics\n","    \"\"\"\n","    model.eval()\n","    all_targets = []\n","    all_predictions = []\n","    all_probs = []  # For AUC calculation in classification\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            x, y = batch\n","            x, y = x.to(device), y.to(device)\n","\n","            # Forward pass depends on model type\n","            if isinstance(model, (VIB, BetaVAE)):\n","                _, _, _, _, pred = model(x)\n","            elif isinstance(model, SparseAutoencoder):\n","                _, _, pred = model(x)\n","            else:  # Standard models like DropoutRegularizedModel\n","                pred = model(x)\n","\n","            # Store predictions and targets\n","            if is_classification:\n","                probs = F.softmax(pred, dim=1) if pred.size(1) > 1 else torch.sigmoid(pred)\n","                _, predicted = torch.max(pred, 1) if pred.size(1) > 1 else (pred > 0.5).long()\n","                all_probs.append(probs.cpu())\n","                all_predictions.append(predicted.cpu())\n","                all_targets.append(y.cpu())\n","            else:\n","                all_predictions.append(pred.cpu())\n","                all_targets.append(y.cpu())\n","\n","    # Concatenate results\n","    if is_classification:\n","        all_targets = torch.cat(all_targets).numpy()\n","        all_predictions = torch.cat(all_predictions).numpy()\n","        all_probs = torch.cat(all_probs).numpy()\n","\n","        # Calculate classification metrics\n","        accuracy = (all_predictions == all_targets).mean()\n","\n","        # For multi-class, calculate macro averages\n","        precision = precision_score(all_targets, all_predictions, average='macro', zero_division=0)\n","        recall = recall_score(all_targets, all_predictions, average='macro', zero_division=0)\n","        f1 = f1_score(all_targets, all_predictions, average='macro', zero_division=0)\n","\n","        # AUC calculation (handle multi-class)\n","        if all_probs.shape[1] > 2:  # Multi-class\n","            # One-hot encode targets for multi-class AUC\n","            from sklearn.preprocessing import label_binarize\n","            classes = list(range(all_probs.shape[1]))\n","            all_targets_binary = label_binarize(all_targets, classes=classes)\n","            auc = roc_auc_score(all_targets_binary, all_probs, multi_class='ovr')\n","        else:  # Binary classification\n","            auc = roc_auc_score(all_targets, all_probs[:, 1] if all_probs.shape[1] > 1 else all_probs)\n","\n","        return {\n","            'accuracy': accuracy,\n","            'precision': precision,\n","            'recall': recall,\n","            'f1_score': f1,\n","            'auc': auc\n","        }\n","    else:\n","        all_targets = torch.cat(all_targets).numpy()\n","        all_predictions = torch.cat(all_predictions).numpy()\n","\n","        # Calculate regression metrics\n","        mse = mean_squared_error(all_targets, all_predictions)\n","        mae = mean_absolute_error(all_targets, all_predictions)\n","        r2 = r2_score(all_targets, all_predictions)\n","\n","        return {\n","            'mse': mse,\n","            'mae': mae,\n","            'rmse': np.sqrt(mse),\n","            'r2_score': r2\n","        }\n","\n","\n","def evaluate_baseline_method(method_name, model, test_loader, device, is_classification=True, k_matrix=None, num_factors=None, latent_dim=None):\n","    \"\"\"\n","    Evaluate a baseline method and compute comprehensive metrics.\n","\n","    Args:\n","        method_name: Name of the method being evaluated\n","        model: The trained model to evaluate\n","        test_loader: DataLoader for test data\n","        device: Device to run evaluation on\n","        is_classification: Whether this is a classification task\n","        k_matrix: Optional K matrix for universal K methods\n","        num_factors: Number of factors for universal K methods\n","        latent_dim: Latent dimension per factor\n","\n","    Returns:\n","        Dictionary of metrics\n","    \"\"\"\n","    task_metrics = evaluate_model_metrics(model, test_loader, device, is_classification)\n","\n","    # Add method-specific metrics\n","    metrics = {\n","        'method': method_name,\n","        'task_metrics': task_metrics\n","    }\n","\n","    # For autoencoder-based methods, add reconstruction metrics\n","    if isinstance(model, (VIB, BetaVAE, SparseAutoencoder)):\n","        model.eval()\n","        recon_loss = 0.0\n","\n","        with torch.no_grad():\n","            for batch in test_loader:\n","                x, y = batch\n","                x, y = x.to(device), y.to(device)\n","\n","                if isinstance(model, (VIB, BetaVAE)):\n","                    x_recon, mu, log_var, z, _ = model(x)\n","                    recon_error = F.mse_loss(x_recon, x).item()\n","\n","                    # Add KL divergence for VIB/VAE models\n","                    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()).item()\n","                    metrics['kl_divergence'] = kl_div / len(test_loader)\n","\n","                    # Add disentanglement metrics if applicable\n","                    if num_factors is not None and latent_dim is not None:\n","                        try:\n","                            z_reshaped = z.view(-1, num_factors, latent_dim)\n","                            metrics['disentanglement'] = {\n","                                'mi_ksg': safe_mi_ksg_estimator(z_reshaped),\n","                                'total_correlation': robust_total_correlation(z_reshaped),\n","                                'modularity': robust_modularity_score(z_reshaped),\n","                                'factor_vae_score': robust_factor_vae_score(z_reshaped),\n","                                'sap_score': robust_sap_score(z_reshaped, x)\n","                            }\n","                        except Exception as e:\n","                            print(f\"Error calculating disentanglement metrics: {e}\")\n","\n","                elif isinstance(model, SparseAutoencoder):\n","                    x_recon, z, _ = model(x)\n","                    recon_error = F.mse_loss(x_recon, x).item()\n","\n","                    # Add sparsity measure\n","                    sparsity = torch.mean(torch.abs(z)).item()\n","                    metrics['sparsity'] = sparsity\n","\n","                recon_loss += recon_error\n","\n","        metrics['recon_error'] = recon_loss / len(test_loader)\n","\n","    # For K-matrix methods, use the evaluate_k_matrix function if provided\n","    if k_matrix is not None and 'Universal_K' in method_name:\n","        try:\n","            k_metrics = evaluate_k_matrix(next(iter(test_loader))[0].to(device), k_matrix, num_factors, latent_dim, device)\n","            metrics['k_metrics'] = k_metrics\n","        except Exception as e:\n","            print(f\"Error evaluating K matrix metrics: {e}\")\n","\n","    return metrics\n","\n","\n","def train_model(model, train_loader, val_loader, device, is_classification=True, epochs=50, patience=5):\n","    \"\"\"\n","    Train a model with early stopping.\n","\n","    Args:\n","        model: The model to train\n","        train_loader: DataLoader for training data\n","        val_loader: DataLoader for validation data\n","        device: Device to run training on\n","        is_classification: Whether this is a classification task\n","        epochs: Maximum number of epochs to train\n","        patience: Number of epochs to wait for improvement before stopping\n","\n","    Returns:\n","        Trained model\n","    \"\"\"\n","    # Set up optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Set up criterion for task loss\n","    if is_classification:\n","        task_criterion = nn.CrossEntropyLoss()\n","    else:\n","        task_criterion = nn.MSELoss()\n","\n","    # Train for specified epochs with early stopping\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        for batch_x, batch_y in train_loader:\n","            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass depends on model type\n","            if isinstance(model, VIB):\n","                x_recon, mu, log_var, z, pred = model(batch_x)\n","                loss, _, _, _ = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","            elif isinstance(model, BetaVAE):\n","                x_recon, mu, log_var, z, pred = model(batch_x)\n","                loss, _, _, _ = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","            elif isinstance(model, SparseAutoencoder):\n","                x_recon, z, pred = model(batch_x)\n","                loss, _, _, _ = model.loss_function(batch_x, x_recon, z, batch_y, pred)\n","            else:  # Standard models like DropoutRegularizedModel\n","                pred = model(batch_x)\n","                loss = task_criterion(pred, batch_y)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for batch_x, batch_y in val_loader:\n","                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","\n","                # Forward pass depends on model type\n","                if isinstance(model, VIB):\n","                    x_recon, mu, log_var, z, pred = model(batch_x)\n","                    _, _, _, task_loss = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","                elif isinstance(model, BetaVAE):\n","                    x_recon, mu, log_var, z, pred = model(batch_x)\n","                    _, _, _, task_loss = model.loss_function(batch_x, x_recon, mu, log_var, batch_y, pred)\n","                elif isinstance(model, SparseAutoencoder):\n","                    x_recon, z, pred = model(batch_x)\n","                    _, _, _, task_loss = model.loss_function(batch_x, x_recon, z, batch_y, pred)\n","                else:  # Standard models\n","                    pred = model(batch_x)\n","                    task_loss = task_criterion(pred, batch_y)\n","\n","                val_loss += task_loss.item()\n","\n","        val_loss /= len(val_loader)\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= patience:\n","                print(f\"Early stopping at epoch {epoch}\")\n","                break\n","\n","    return model\n","\n","\n","def save_metrics_to_csv(results, output_dir='.'):\n","    \"\"\"\n","    Save experiment results to CSV files.\n","\n","    Args:\n","        results: Dictionary of results by dataset and method\n","        output_dir: Directory to save CSV files\n","    \"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Create consolidated dataframes\n","    all_task_metrics = []\n","    all_disent_metrics = []\n","\n","    # Process each dataset\n","    for dataset_name, dataset_results in results.items():\n","        # 1. Task performance\n","\n","        # K matrix methods\n","        if 'k_methods' in dataset_results:\n","            for method_name, method_results in dataset_results['k_methods'].items():\n","                for result in method_results:\n","                    row = {\n","                        'dataset': dataset_name,\n","                        'method': f\"{method_name}\",\n","                        'method_type': 'Universal_K',\n","                        'num_factors': result['num_factors'],\n","                        'latent_dim': result['latent_dim']\n","                    }\n","\n","                    # Add task metrics\n","                    if 'teacher_performance' in result:\n","                        is_classification = isinstance(result['teacher_performance'], float) and 0 <= result['teacher_performance'] <= 1\n","\n","                        if is_classification:\n","                            row['accuracy'] = result['teacher_performance']\n","                        else:\n","                            row['mse'] = result['teacher_performance']\n","\n","                    # Add K matrix metrics\n","                    if 'metrics' in result:\n","                        metrics = result['metrics']\n","                        for metric_name, metric_value in metrics.items():\n","                            row[metric_name] = metric_value\n","\n","                    # Add other fields\n","                    if 'combined_score' in result:\n","                        row['combined_score'] = result['combined_score']\n","                    if 'init_time' in result:\n","                        row['init_time'] = result['init_time']\n","                    if 'refine_time' in result:\n","                        row['refine_time'] = result['refine_time']\n","\n","                    all_task_metrics.append(row)\n","\n","                    # Also add to disentanglement metrics\n","                    disent_row = row.copy()\n","                    if 'metrics' in result:\n","                        metrics = result['metrics']\n","                        disentanglement_metrics = ['mi_ksg', 'modularity', 'total_correlation',\n","                                                'factor_vae_score', 'sap_score', 'sparsity', 'variance_ratio']\n","\n","                        for metric in disentanglement_metrics:\n","                            if metric in metrics:\n","                                disent_row[metric] = metrics[metric]\n","\n","                        all_disent_metrics.append(disent_row)\n","\n","        # Baseline methods\n","        if 'baseline_methods' in dataset_results:\n","            for method_name, method_results in dataset_results['baseline_methods'].items():\n","                for result in method_results:\n","                    row = {\n","                        'dataset': dataset_name,\n","                        'method': method_name,\n","                        'method_type': 'Baseline'\n","                    }\n","\n","                    # Add hyperparameters if available\n","                    if 'params' in result:\n","                        for param_name, param_value in result['params'].items():\n","                            row[param_name] = param_value\n","\n","                    # Add num_factors and latent_dim if available\n","                    if 'num_factors' in result:\n","                        row['num_factors'] = result['num_factors']\n","                    if 'latent_dim' in result:\n","                        row['latent_dim'] = result['latent_dim']\n","\n","                    # Add metrics\n","                    if 'metrics' in result:\n","                        metrics = result['metrics']\n","                        for metric_name, metric_value in metrics.items():\n","                            if not isinstance(metric_value, dict):\n","                                row[metric_name] = metric_value\n","\n","                    # Add performance if available\n","                    if 'performance' in result:\n","                        is_classification = isinstance(result['performance'], float) and 0 <= result['performance'] <= 1\n","\n","                        if is_classification:\n","                            row['accuracy'] = result['performance']\n","                        else:\n","                            row['mse'] = result['performance']\n","\n","                    all_task_metrics.append(row)\n","\n","        # Knowledge Distillation\n","        if 'KnowledgeDistillation' in dataset_results:\n","            for result in dataset_results['KnowledgeDistillation']:\n","                row = {\n","                    'dataset': dataset_name,\n","                    'method': 'KnowledgeDistillation',\n","                    'method_type': 'Distillation',\n","                    'temperature': result['temperature'],\n","                    'alpha': result['alpha'],\n","                    'teacher_method': result['teacher_method'],\n","                    'num_factors': result['num_factors'],\n","                    'latent_dim': result['latent_dim']\n","                }\n","\n","                # Add metrics\n","                if 'metrics' in result:\n","                    metrics = result['metrics']\n","                    for metric_name, metric_value in metrics.items():\n","                        row[metric_name] = metric_value\n","\n","                # Add performance if available\n","                if 'performance' in result:\n","                    is_classification = isinstance(result['performance'], float) and 0 <= result['performance'] <= 1\n","\n","                    if is_classification:\n","                        row['accuracy'] = result['performance']\n","                    else:\n","                        row['mse'] = result['performance']\n","\n","                all_task_metrics.append(row)\n","\n","    # Save consolidated dataframes\n","    if all_task_metrics:\n","        df_all_task = pd.DataFrame(all_task_metrics)\n","        df_all_task.to_csv(f\"{output_dir}/all_task_metrics.csv\", index=False)\n","        print(f\"Saved all task metrics to {output_dir}/all_task_metrics.csv\")\n","\n","    if all_disent_metrics:\n","        df_all_disent = pd.DataFrame(all_disent_metrics)\n","        df_all_disent.to_csv(f\"{output_dir}/all_disentanglement_metrics.csv\", index=False)\n","        print(f\"Saved all disentanglement metrics to {output_dir}/all_disentanglement_metrics.csv\")\n","\n","    # Also save separate files for each dataset for compatibility\n","    for dataset_name, dataset_results in results.items():\n","        dataset_task_metrics = [row for row in all_task_metrics if row['dataset'] == dataset_name]\n","        dataset_disent_metrics = [row for row in all_disent_metrics if row['dataset'] == dataset_name]\n","\n","        if dataset_task_metrics:\n","            df_task = pd.DataFrame(dataset_task_metrics)\n","            df_task.to_csv(f\"{output_dir}/{dataset_name}_task_metrics.csv\", index=False)\n","            print(f\"Saved {dataset_name} task metrics to {output_dir}/{dataset_name}_task_metrics.csv\")\n","\n","        if dataset_disent_metrics:\n","            df_disent = pd.DataFrame(dataset_disent_metrics)\n","            df_disent.to_csv(f\"{output_dir}/{dataset_name}_disentanglement_metrics.csv\", index=False)\n","            print(f\"Saved {dataset_name} disentanglement metrics to {output_dir}/{dataset_name}_disentanglement_metrics.csv\")\n","\n","\n","def run_distillation_experiment(best_k_method, best_k_matrix, num_factors, latent_dim,\n","                               x_train, y_train, x_val, y_val, x_test, y_test,\n","                               is_classification, device, alphas=[0.3, 0.5, 0.7]):\n","    \"\"\"\n","    Run knowledge distillation experiment using the universal K matrix.\n","\n","    Args:\n","        best_k_method: Name of the best K matrix method\n","        best_k_matrix: The best K matrix to use for distillation\n","        num_factors, latent_dim: Configuration of the K matrix\n","        x_train, y_train, x_val, y_val, x_test, y_test: Data splits\n","        is_classification: Whether this is a classification task\n","        device: Device to run on\n","        alphas: List of alpha values to try (weighting between distillation and task loss)\n","\n","    Returns:\n","        Dictionary of distillation results\n","    \"\"\"\n","    # Create results container\n","    results = []\n","\n","    # Move data to device\n","    best_k_matrix = best_k_matrix.to(device)\n","    x_train, y_train = x_train.to(device), y_train.to(device)\n","    x_val, y_val = x_val.to(device), y_val.to(device)\n","    x_test, y_test = x_test.to(device), y_test.to(device)\n","\n","    # Encode data with K matrix\n","    z_train = encode_data(x_train, best_k_matrix)\n","    z_val = encode_data(x_val, best_k_matrix)\n","    z_test = encode_data(x_test, best_k_matrix)\n","\n","    # Flatten z for training\n","    z_train_flat = z_train.reshape(z_train.shape[0], -1)\n","    z_val_flat = z_val.reshape(z_val.shape[0], -1)\n","    z_test_flat = z_test.reshape(z_test.shape[0], -1)\n","\n","    # Determine input dimension for teacher/student models\n","    input_dim = z_train_flat.shape[1]\n","\n","    # Create teacher model (larger)\n","    if is_classification:\n","        num_classes = len(torch.unique(y_train))\n","        teacher_model = nn.Sequential(\n","            nn.Linear(input_dim, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, num_classes)\n","        ).to(device)\n","    else:\n","        teacher_model = nn.Sequential(\n","            nn.Linear(input_dim, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 1)\n","        ).to(device)\n","\n","    # Create latent datasets\n","    latent_train_dataset = TensorDataset(z_train_flat, y_train)\n","    latent_val_dataset = TensorDataset(z_val_flat, y_val)\n","    latent_test_dataset = TensorDataset(z_test_flat, y_test)\n","\n","    batch_size = 128\n","    latent_train_loader = DataLoader(latent_train_dataset, batch_size=batch_size, shuffle=True)\n","    latent_val_loader = DataLoader(latent_val_dataset, batch_size=batch_size)\n","    latent_test_loader = DataLoader(latent_test_dataset, batch_size=batch_size)\n","\n","    # Train teacher model\n","    teacher_model = train_model(teacher_model, latent_train_loader, latent_val_loader, device, is_classification)\n","\n","    # Evaluate teacher model\n","    teacher_metrics = evaluate_model_metrics(teacher_model, latent_test_loader, device, is_classification)\n","\n","    # For each alpha value, train a student model\n","    for alpha in alphas:\n","        # Create student model (smaller)\n","        if is_classification:\n","            student_model = nn.Sequential(\n","                nn.Linear(input_dim, 64),\n","                nn.ReLU(),\n","                nn.Linear(64, num_classes)\n","            ).to(device)\n","        else:\n","            student_model = nn.Sequential(\n","                nn.Linear(input_dim, 64),\n","                nn.ReLU(),\n","                nn.Linear(64, 1)\n","            ).to(device)\n","\n","        # Train student with knowledge distillation\n","        optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n","\n","        # Training with early stopping\n","        best_val_loss = float('inf')\n","        patience = 5\n","        early_stop_counter = 0\n","\n","        for epoch in range(50):  # 50 epochs max\n","            # Training\n","            student_model.train()\n","            teacher_model.eval()\n","\n","            for batch_z, batch_y in latent_train_loader:\n","                optimizer.zero_grad()\n","\n","                # Get teacher outputs (with no grad)\n","                with torch.no_grad():\n","                    teacher_outputs = teacher_model(batch_z)\n","\n","                # Get student outputs\n","                student_outputs = student_model(batch_z)\n","\n","                # Knowledge distillation loss\n","                distill_loss = knowledge_distillation_loss(\n","                    student_outputs, teacher_outputs, batch_y,\n","                    temperature=4.0, alpha=alpha\n","                )\n","\n","                distill_loss.backward()\n","                optimizer.step()\n","\n","            # Validation\n","            student_model.eval()\n","            val_loss = 0.0\n","\n","            with torch.no_grad():\n","                for batch_z, batch_y in latent_val_loader:\n","                    student_outputs = student_model(batch_z)\n","\n","                    if is_classification:\n","                        loss = F.cross_entropy(student_outputs, batch_y)\n","                    else:\n","                        loss = F.mse_loss(student_outputs, batch_y)\n","\n","                    val_loss += loss.item()\n","\n","            val_loss /= len(latent_val_loader)\n","\n","            # Early stopping\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                early_stop_counter = 0\n","            else:\n","                early_stop_counter += 1\n","                if early_stop_counter >= patience:\n","                    print(f\"Early stopping at epoch {epoch}\")\n","                    break\n","\n","        # Evaluate student model\n","        student_metrics = evaluate_model_metrics(student_model, latent_test_loader, device, is_classification)\n","\n","        # Calculate model sizes\n","        teacher_size = sum(p.numel() for p in teacher_model.parameters())\n","        student_size = sum(p.numel() for p in student_model.parameters())\n","\n","        # Add result\n","        result = {\n","            'method': 'KnowledgeDistillation',\n","            'alpha': alpha,\n","            'k_method': best_k_method,\n","            'num_factors': num_factors,\n","            'latent_dim': latent_dim,\n","            'teacher_metrics': teacher_metrics,\n","            'student_metrics': student_metrics,\n","            'teacher_size': teacher_size,\n","            'student_size': student_size,\n","            'compression_ratio': teacher_size / student_size\n","        }\n","\n","        results.append(result)\n","\n","    return results\n","\n","def run_single_dataset_experiment(dataset_name, output_dir, gpu_id, results_queue, k_methods, epochs=100):\n","    \"\"\"\n","    Run experiment for a single dataset using only the top K matrix methods.\n","\n","    Args:\n","        dataset_name: Name of the dataset\n","        output_dir: Directory for output\n","        gpu_id: GPU ID to use\n","        results_queue: Queue for results\n","        k_methods: Methods to evaluate (only Clustered, PCA, FactorAnalysis)\n","        epochs: Number of epochs for refinement\n","\n","    Returns:\n","        None (results sent to queue)\n","    \"\"\"\n","    try:\n","        # Set up device\n","        device = setup_device(gpu_id)\n","        print(f\"Processing {dataset_name} on {device}\")\n","\n","        # Load dataset\n","        available_datasets = get_available_datasets()\n","        if not available_datasets.get(dataset_name, {}).get('available', False):\n","            raise ValueError(f\"Dataset {dataset_name} is not available\")\n","\n","        # Load dataset\n","        x_data, y_data, is_classification = load_or_create_dataset(dataset_name, available_datasets)\n","        print(f\"Dataset shape: {x_data.shape}, Classification: {is_classification}\")\n","\n","        # Define factors to try - using only k=3 and k=5 as specified in the paper\n","        # Fix dimension to 8 as requested\n","        factors_to_try = [3, 5]\n","        latent_dim = 8  # Fixed dimension\n","\n","        # Initialize results for this dataset\n","        dataset_results = {'k_methods': {}}\n","\n","        # Process each K method (Clustered, PCA, FactorAnalysis)\n","        for method_name, method_func in k_methods:\n","            print(f\"\\nEvaluating method: {method_name} for {dataset_name}\")\n","            method_results = []\n","\n","            for num_factors in factors_to_try:\n","                config_info = f\"[{method_name}, Factors={num_factors}, Dims={latent_dim}]\"\n","                print(f\"Processing {config_info}\")\n","\n","                try:\n","                    # Initialize K matrix\n","                    start_time = time.time()\n","                    k_matrix = method_func(x_data.to(device), num_factors, latent_dim, device)\n","                    init_time = time.time() - start_time\n","\n","                    # Refine K matrix\n","                    start_time = time.time()\n","                    k_refined = refine_k_matrix(x_data.to(device), k_matrix, num_factors, latent_dim, device, epochs=epochs)\n","                    refine_time = time.time() - start_time\n","\n","                    # Evaluate K matrix\n","                    metrics = evaluate_k_matrix(x_data.to(device), k_refined, num_factors, latent_dim, device)\n","\n","                    # Calculate combined score as specified in the paper\n","                    combined_score = (\n","                        (1.0 - metrics['mi_ksg']) * 0.2 +\n","                        metrics['modularity'] * 0.2 +\n","                        (1.0 - metrics['total_correlation']) * 0.2 +\n","                        metrics['factor_vae_score'] * 0.2 +\n","                        metrics['sap_score'] * 0.2\n","                    )\n","\n","                    # Add results\n","                    result = {\n","                        'method': method_name,\n","                        'num_factors': num_factors,\n","                        'latent_dim': latent_dim,\n","                        'metrics': metrics,\n","                        'combined_score': combined_score,\n","                        'init_time': init_time,\n","                        'refine_time': refine_time,\n","                        'k_matrix': k_refined.detach().cpu()\n","                    }\n","\n","                    # For evaluation, also store teacher performance\n","                    # Encode data with K matrix\n","                    z = encode_data(x_data.to(device), k_refined)\n","\n","                    # Flatten z for prediction\n","                    z_flat = z.reshape(z.shape[0], -1)\n","\n","                    # Split data for training\n","                    train_size = int(0.8 * len(z_flat))\n","                    train_z, test_z = z_flat[:train_size], z_flat[train_size:]\n","                    train_y, test_y = y_data[:train_size].to(device), y_data[train_size:].to(device)\n","\n","                    # Create prediction model\n","                    input_dim = z_flat.shape[1]\n","                    if is_classification:\n","                        num_classes = len(torch.unique(y_data))\n","                        model = nn.Sequential(\n","                            nn.Linear(input_dim, 64),\n","                            nn.ReLU(),\n","                            nn.Linear(64, num_classes)\n","                        ).to(device)\n","                        criterion = nn.CrossEntropyLoss()\n","                    else:\n","                        model = nn.Sequential(\n","                            nn.Linear(input_dim, 64),\n","                            nn.ReLU(),\n","                            nn.Linear(64, 1)\n","                        ).to(device)\n","                        criterion = nn.MSELoss()\n","\n","                    # Train simple model to evaluate representation quality\n","                    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","                    model.train()\n","\n","                    # Train for 20 epochs\n","                    batch_size = 128\n","                    for _ in range(20):\n","                        for i in range(0, len(train_z), batch_size):\n","                            batch_z = train_z[i:i+batch_size]\n","                            batch_y = train_y[i:i+batch_size]\n","\n","                            optimizer.zero_grad()\n","                            outputs = model(batch_z)\n","\n","                            if is_classification:\n","                                loss = criterion(outputs, batch_y.long())\n","                            else:\n","                                loss = criterion(outputs, batch_y)\n","\n","                            loss.backward()\n","                            optimizer.step()\n","\n","                    # Evaluate model\n","                    model.eval()\n","                    with torch.no_grad():\n","                        outputs = model(test_z)\n","\n","                        if is_classification:\n","                            _, predicted = torch.max(outputs, 1)\n","                            accuracy = (predicted == test_y.long()).float().mean().item()\n","                            result['teacher_performance'] = accuracy\n","                        else:\n","                            mse = criterion(outputs, test_y).item()\n","                            result['teacher_performance'] = mse\n","\n","                    method_results.append(result)\n","\n","                    # Log results\n","                    print(f\"{config_info} - Combined score: {combined_score:.4f}\")\n","                    performance_metric = \"Accuracy\" if is_classification else \"MSE\"\n","                    print(f\"{config_info} - {performance_metric}: {result['teacher_performance']:.4f}\")\n","\n","                    # Clean up GPU memory\n","                    clean_gpu_memory(device)\n","\n","                except Exception as e:\n","                    print(f\"Error processing {config_info}: {e}\")\n","                    import traceback\n","                    traceback.print_exc()\n","                    clean_gpu_memory(device)\n","\n","            # Store results for this method\n","            dataset_results['k_methods'][method_name] = method_results\n","\n","        # Put results in queue\n","        results_queue.put((dataset_name, dataset_results))\n","        print(f\"Completed processing dataset: {dataset_name}\")\n","\n","    except Exception as e:\n","        print(f\"Error processing dataset {dataset_name}: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        # Return empty results on error\n","        results_queue.put((dataset_name, {'k_methods': {}}))\n","\n","    finally:\n","        # Clean up GPU memory\n","        if 'device' in locals():\n","            clean_gpu_memory(device)\n","\n","\n","def save_metrics_for_sota_comparison(results, output_dir='.'):\n","    \"\"\"\n","    Save experiment results to CSV files specifically formatted for SOTA comparison.\n","\n","    Args:\n","        results: Dictionary of results by dataset and method\n","        output_dir: Directory to save CSV files\n","    \"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Create consolidated dataframes\n","    all_task_metrics = []\n","    all_disent_metrics = []\n","    sota_comparison = []\n","\n","    # Process each dataset\n","    for dataset_name, dataset_results in results.items():\n","        # 1. K matrix methods\n","        if 'k_methods' in dataset_results:\n","            for method_name, method_results in dataset_results['k_methods'].items():\n","                for result in method_results:\n","                    # Basic information\n","                    row = {\n","                        'dataset': dataset_name,\n","                        'method': method_name,\n","                        'num_factors': result['num_factors'],\n","                        'latent_dim': result['latent_dim'],\n","                        'config': f\"f{result['num_factors']}_d{result['latent_dim']}\"\n","                    }\n","\n","                    # Performance metrics\n","                    if 'teacher_performance' in result:\n","                        is_classification = isinstance(result['teacher_performance'], float) and 0 <= result['teacher_performance'] <= 1\n","                        if is_classification:\n","                            row['accuracy'] = result['teacher_performance']\n","                        else:\n","                            row['mse'] = result['teacher_performance']\n","\n","                    # Add K matrix metrics\n","                    if 'metrics' in result:\n","                        metrics = result['metrics']\n","                        for metric_name, metric_value in metrics.items():\n","                            row[metric_name] = metric_value\n","\n","                    # Add combined score\n","                    if 'combined_score' in result:\n","                        row['combined_score'] = result['combined_score']\n","\n","                    # Timing information\n","                    if 'init_time' in result:\n","                        row['init_time'] = result['init_time']\n","                    if 'refine_time' in result:\n","                        row['refine_time'] = result['refine_time']\n","\n","                    # Add to all metrics\n","                    all_task_metrics.append(row)\n","\n","                    # Add to SOTA comparison format\n","                    sota_row = row.copy()\n","                    sota_row['method_type'] = 'Universal_K'\n","                    sota_comparison.append(sota_row)\n","\n","                    # Add disentanglement metrics\n","                    disent_row = row.copy()\n","                    if 'metrics' in result:\n","                        metrics = result['metrics']\n","                        disentanglement_metrics = ['mi_ksg', 'modularity', 'total_correlation',\n","                                                'factor_vae_score', 'sap_score', 'sparsity', 'variance_ratio']\n","\n","                        for metric in disentanglement_metrics:\n","                            if metric in metrics:\n","                                disent_row[metric] = metrics[metric]\n","\n","                        all_disent_metrics.append(disent_row)\n","\n","    # Save consolidated dataframes\n","    if all_task_metrics:\n","        df_all_task = pd.DataFrame(all_task_metrics)\n","        df_all_task.to_csv(f\"{output_dir}/all_task_metrics.csv\", index=False)\n","        print(f\"Saved all task metrics to {output_dir}/all_task_metrics.csv\")\n","\n","    if all_disent_metrics:\n","        df_all_disent = pd.DataFrame(all_disent_metrics)\n","        df_all_disent.to_csv(f\"{output_dir}/all_disentanglement_metrics.csv\", index=False)\n","        print(f\"Saved all disentanglement metrics to {output_dir}/all_disentanglement_metrics.csv\")\n","\n","    # Save SOTA comparison\n","    if sota_comparison:\n","        df_sota = pd.DataFrame(sota_comparison)\n","        df_sota.to_csv(f\"{output_dir}/sota_comparison.csv\", index=False)\n","        print(f\"Saved SOTA comparison to {output_dir}/sota_comparison.csv\")\n","\n","    # Save metrics by dataset and method\n","    if all_task_metrics:\n","        # Group by dataset and method\n","        for dataset_name in set(row['dataset'] for row in all_task_metrics):\n","            dataset_metrics = [row for row in all_task_metrics if row['dataset'] == dataset_name]\n","\n","            # Create a DataFrame and save\n","            df_dataset = pd.DataFrame(dataset_metrics)\n","            df_dataset.to_csv(f\"{output_dir}/{dataset_name}_metrics.csv\", index=False)\n","            print(f\"Saved {dataset_name} metrics to {output_dir}/{dataset_name}_metrics.csv\")\n","\n","            # Group by method\n","            for method_name in set(row['method'] for row in dataset_metrics):\n","                method_metrics = [row for row in dataset_metrics if row['method'] == method_name]\n","\n","                # Create a DataFrame and save\n","                df_method = pd.DataFrame(method_metrics)\n","                df_method.to_csv(f\"{output_dir}/{dataset_name}_{method_name}_metrics.csv\", index=False)\n","                print(f\"Saved {dataset_name}_{method_name} metrics to {output_dir}/{dataset_name}_{method_name}_metrics.csv\")\n","\n","def generate_stats_table(results, output_dir='.'):\n","    \"\"\"\n","    Generate and save statistical tables for comparing methods.\n","\n","    Args:\n","        results: Dictionary of results by dataset and method\n","        output_dir: Directory to save tables\n","    \"\"\"\n","    # Create tables for different hyperparameter configurations\n","    for factors in [3, 5]:\n","        for dims in [8, 16]:\n","            rows = []\n","\n","            # Process each dataset\n","            for dataset_name, dataset_results in results.items():\n","                if 'k_methods' not in dataset_results:\n","                    continue\n","\n","                # Find best method for this dataset and config\n","                best_score = -float('inf')\n","                best_method = None\n","                method_scores = {}\n","                method_metrics = {}\n","\n","                for method_name, method_results in dataset_results['k_methods'].items():\n","                    for result in method_results:\n","                        if result['num_factors'] == factors and result['latent_dim'] == dims:\n","                            score = result['combined_score']\n","                            method_scores[method_name] = score\n","\n","                            # Store metrics\n","                            if 'metrics' in result:\n","                                method_metrics[method_name] = result['metrics']\n","\n","                            # Update best method\n","                            if score > best_score:\n","                                best_score = score\n","                                best_method = method_name\n","\n","                # Create row\n","                if best_method:\n","                    row = {\n","                        'dataset': dataset_name,\n","                        'best_method': best_method,\n","                        'best_score': best_score\n","                    }\n","\n","                    # Add scores for each method\n","                    for method_name in ['Clustered', 'PCA', 'FactorAnalysis']:\n","                        if method_name in method_scores:\n","                            row[f\"{method_name}_score\"] = method_scores[method_name]\n","                        else:\n","                            row[f\"{method_name}_score\"] = None\n","\n","                    # Add key metrics for best method\n","                    if best_method in method_metrics:\n","                        metrics = method_metrics[best_method]\n","                        for metric_name in ['mi_ksg', 'modularity', 'sparsity', 'recon_error']:\n","                            if metric_name in metrics:\n","                                row[metric_name] = metrics[metric_name]\n","\n","                    rows.append(row)\n","\n","            # Create and save table\n","            if rows:\n","                df = pd.DataFrame(rows)\n","                filename = f\"{output_dir}/stats_f{factors}_d{dims}.csv\"\n","                df.to_csv(filename, index=False)\n","                print(f\"Saved statistical table for f{factors}_d{dims} to {filename}\")\n","\n","    # Create overall best method table\n","    create_best_method_table(results, output_dir)\n","\n","def create_best_method_table(results, output_dir='.'):\n","    \"\"\"\n","    Create a table showing the best method for each dataset across all configurations.\n","\n","    Args:\n","        results: Dictionary of results by dataset and method\n","        output_dir: Directory to save table\n","    \"\"\"\n","    rows = []\n","\n","    for dataset_name, dataset_results in results.items():\n","        if 'k_methods' not in dataset_results:\n","            continue\n","\n","        # Find best method and configuration\n","        best_score = -float('inf')\n","        best_config = None\n","\n","        for method_name, method_results in dataset_results['k_methods'].items():\n","            for result in method_results:\n","                if 'combined_score' in result and result['combined_score'] > best_score:\n","                    best_score = result['combined_score']\n","                    best_config = {\n","                        'dataset': dataset_name,\n","                        'method': method_name,\n","                        'factors': result['num_factors'],\n","                        'dims': result['latent_dim'],\n","                        'combined_score': result['combined_score']\n","                    }\n","\n","                    # Add metrics\n","                    if 'metrics' in result:\n","                        metrics = result['metrics']\n","                        for metric_name, metric_value in metrics.items():\n","                            best_config[metric_name] = metric_value\n","\n","        if best_config:\n","            rows.append(best_config)\n","\n","    # Create and save table\n","    if rows:\n","        df = pd.DataFrame(rows)\n","        filename = f\"{output_dir}/best_methods_overall.csv\"\n","        df.to_csv(filename, index=False)\n","        print(f\"Saved best methods table to {filename}\")\n","\n","        # Also create a formatted table for the paper\n","        paper_rows = []\n","        for row in rows:\n","            paper_row = {\n","                'Dataset': row['dataset'],\n","                'Best Method': row['method'],\n","                'Combined Score': f\"{row['combined_score']:.4f}\",\n","                'Recon. Error': f\"{row.get('recon_error', 'N/A'):.4f}\" if isinstance(row.get('recon_error'), (int, float)) else 'N/A',\n","                'MI (MINE)': f\"{row.get('mi_ksg', 'N/A'):.4f}\" if isinstance(row.get('mi_ksg'), (int, float)) else 'N/A',\n","                'Sparsity': f\"{row.get('sparsity', 'N/A'):.4f}\" if isinstance(row.get('sparsity'), (int, float)) else 'N/A'\n","            }\n","            paper_rows.append(paper_row)\n","\n","        # Create and save paper table\n","        df_paper = pd.DataFrame(paper_rows)\n","        paper_filename = f\"{output_dir}/paper_table.csv\"\n","        df_paper.to_csv(paper_filename, index=False)\n","        print(f\"Saved formatted paper table to {paper_filename}\")\n","\n","def run_parallel_experiments(dataset_names, output_dir, max_processes, results_queue=None, k_methods=None, epochs=100):\n","    \"\"\"\n","    Run experiments in parallel across multiple GPUs/processes, focusing on top K-matrix methods.\n","\n","    Args:\n","        dataset_names: List of datasets to process\n","        output_dir: Directory for saving results\n","        max_processes: Maximum number of parallel processes\n","        results_queue: Optional Queue for collecting results\n","        k_methods: List of K matrix methods to evaluate\n","        epochs: Number of epochs for refining K matrices\n","\n","    Returns:\n","        Combined results dictionary\n","    \"\"\"\n","    if results_queue is None:\n","        manager = Manager()\n","        results_queue = manager.Queue()\n","\n","    # Define only the top methods (Clustered, PCA, FactorAnalysis)\n","    if k_methods is None:\n","        k_methods = [\n","            ('Clustered', create_clustered_k_matrix),\n","            ('PCA', create_pca_k_matrix),\n","            ('FactorAnalysis', create_factor_analysis_k_matrix)\n","        ]\n","\n","    # Create process pool\n","    all_results = {}\n","\n","    # Process datasets in batches\n","    for i in range(0, len(dataset_names), max_processes):\n","        batch = dataset_names[i:i + max_processes]\n","        processes = []\n","        active_datasets = []\n","\n","        # Start processes for this batch\n","        for j, dataset_name in enumerate(batch):\n","            # Assign GPU\n","            gpu_id = j % max(1, torch.cuda.device_count()) if torch.cuda.is_available() else None\n","\n","            # Create and start process\n","            p = Process(\n","                target=run_single_dataset_experiment,\n","                args=(dataset_name, output_dir, gpu_id, results_queue, k_methods, epochs)\n","            )\n","            processes.append(p)\n","            active_datasets.append(dataset_name)\n","            p.start()\n","            print(f\"Started processing {dataset_name} on GPU {gpu_id if gpu_id is not None else 'N/A'}\")\n","\n","        # Wait for all processes in this batch to complete\n","        for p in processes:\n","            p.join()\n","\n","        # Collect results from this batch\n","        for _ in range(len(active_datasets)):\n","            try:\n","                dataset_name, dataset_results = results_queue.get(timeout=10)\n","                all_results[dataset_name] = dataset_results\n","                print(f\"Collected results for {dataset_name}\")\n","            except Exception as e:\n","                print(f\"Error collecting results: {e}\")\n","\n","        # Save intermediate results\n","        if all_results:\n","            save_metrics_for_sota_comparison(all_results, output_dir)\n","\n","    return all_results\n","\n","# ===== MAIN ENTRY POINT =====\n","def main(dataset_names=None, output_dir='results', max_processes=None, epochs=100):\n","    \"\"\"\n","    Modified main function to run the Universal K Matrix experiment focused on top methods.\n","\n","    Args:\n","        dataset_names: List of datasets to test (None for all available)\n","        output_dir: Directory to save results\n","        max_processes: Maximum number of parallel processes (None uses all available GPUs)\n","        epochs: Number of epochs for refining K matrices\n","\n","    Returns:\n","        Dictionary of results and comparison DataFrame\n","    \"\"\"\n","    try:\n","        print(\"Starting Universal K Matrix Analysis with Top Methods\")\n","\n","        # Create output directory\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        # Record start time\n","        start_time = time.time()\n","\n","        # Set up multiprocessing with 'spawn' method for CUDA compatibility\n","        try:\n","            set_start_method('spawn', force=True)\n","        except RuntimeError:\n","            print(\"Context already set, continuing...\")\n","\n","        # Set up GPU management\n","        num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n","        print(f\"Found {num_gpus} GPUs\")\n","\n","        # Determine maximum parallel processes\n","        if max_processes is None:\n","            max_processes = max(1, num_gpus)\n","        print(f\"Using maximum of {max_processes} parallel processes\")\n","\n","        # Get available datasets\n","        available_datasets = get_available_datasets()\n","        if dataset_names is None:\n","            dataset_names = [name for name, info in available_datasets.items() if info['available']]\n","\n","        if not dataset_names:\n","            print(\"No datasets available for processing\")\n","            return {}\n","\n","        print(f\"Processing datasets: {', '.join(dataset_names)}\")\n","\n","        # Define ONLY the top methods to test based on the paper results\n","        k_methods = [\n","            ('Clustered', create_clustered_k_matrix),\n","            ('PCA', create_pca_k_matrix),\n","            ('FactorAnalysis', create_factor_analysis_k_matrix)\n","        ]\n","\n","        # Create Manager for shared resources\n","        manager = Manager()\n","        results_queue = manager.Queue()\n","\n","        # Run experiment using parallel processes\n","        results = run_parallel_experiments(dataset_names, output_dir, max_processes,\n","                                          results_queue, k_methods, epochs=epochs)\n","\n","        # Save results to CSV specifically formatted for SOTA comparison\n","        save_metrics_for_sota_comparison(results, output_dir)\n","\n","        # Generate comparison between methods\n","        comparison_df = compare_universal_k_methods(results)\n","\n","        # Save comparison to CSV\n","        comparison_path = os.path.join(output_dir, 'method_comparison.csv')\n","        comparison_df.to_csv(comparison_path, index=False)\n","        print(f\"Saved method comparison to {comparison_path}\")\n","\n","        # Generate statistics table for the paper\n","        generate_stats_table(results, output_dir)\n","\n","        # Print elapsed time\n","        elapsed_time = time.time() - start_time\n","        print(f\"Experiment completed in {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n","\n","        return results, comparison_df\n","\n","    except Exception as e:\n","        print(f\"Error in main: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None, None\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}